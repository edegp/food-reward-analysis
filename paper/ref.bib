@article{Dwivedi2021,
  author = {Dwivedi, Kshitij and Bonner, Michael F. and Cichy, Radoslaw Martin and Roig, Gemma},
  title = {Unveiling functions of the visual cortex using task-specific deep neural networks},
  journal = {PLOS Computational Biology},
  volume = {17},
  number = {8},
  pages = {e1009267},
  year = {2021},
  doi = {10.1371/journal.pcbi.1009267}
}

@article{Kriegeskorte2008,
  author = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter},
  title = {Representational similarity analysis - connecting the branches of systems neuroscience},
  journal = {Frontiers in Systems Neuroscience},
  volume = {2},
  pages = {4},
  year = {2008},
  doi = {10.3389/neuro.06.004.2008}
}

@inproceedings{Kornblith2019,
  author = {Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  title = {Similarity of neural network representations revisited},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages = {3519--3529},
  year = {2019},
  volume = {97},
  series = {Proceedings of Machine Learning Research},
  publisher = {PMLR}
}

@inproceedings{Williams2024,
  author = {Williams, Alex H.},
  title = {Equivalence between representational similarity analysis, centered kernel alignment, and canonical correlations analysis},
  booktitle = {Proceedings of UniReps: the Second Edition of the Workshop on Unifying Representations in Neural Models},
  pages = {10--23},
  year = {2024},
  volume = {285},
  series = {Proceedings of Machine Learning Research},
  publisher = {PMLR}
}

@article{Mumford2012,
  author = {Mumford, Jeanette A. and Turner, Benjamin O. and Ashby, F. Gregory and Poldrack, Russell A.},
  title = {Deconvolving {BOLD} activation in event-related designs for multivoxel pattern classification analyses},
  journal = {NeuroImage},
  volume = {59},
  number = {3},
  pages = {2636--2643},
  year = {2012},
  doi = {10.1016/j.neuroimage.2011.08.076}
}

@article{Chen2025,
  author = {Chen, Haoyang and Liu, Boyu and Wang, Shuo and Bi, Yanchao},
  title = {Combined evidence from artificial neural networks and human brain-lesion models reveals that language modulates vision in human perception},
  journal = {Nature Human Behaviour},
  year = {2025},
  doi = {10.1038/s41562-025-02357-5}
}

@article{Foroni2016,
  author = {Foroni, Francesco and Pergola, Giulio and Rumiati, Raffaella I.},
  title = {Food color is in the eye of the beholder: the role of human trichromatic vision in food evaluation},
  journal = {Scientific Reports},
  volume = {6},
  pages = {37034},
  year = {2016},
  doi = {10.1038/srep37034}
}

@article{Makris2006,
  author = {Makris, Nikos and Goldstein, Jill M. and Kennedy, David and Hodge, Steven M. and Caviness, Verne S. and Faraone, Stephen V. and Tsuang, Ming T. and Seidman, Larry J.},
  title = {Decreased volume of left and total anterior insular lobule in schizophrenia},
  journal = {Schizophrenia Research},
  volume = {83},
  number = {2-3},
  pages = {155--171},
  year = {2006},
  doi = {10.1016/j.schres.2005.11.020}
}

@article{Frazier2005,
  author = {Frazier, Jean A. and Chiu, Sandra and Breeze, Janis L. and Makris, Nikos and Lange, Nicholas and Kennedy, David N. and Herbert, Martha R. and Bent, Eileen K. and Koneru, Vamsi K. and Dieterich, Megan E. and Hodge, Steven M. and Rauch, Scott L. and Grant, P. Ellen and Cohen, Bruce M. and Seidman, Larry J. and Caviness, Verne S. and Biederman, Joseph},
  title = {Structural brain magnetic resonance imaging of limbic and thalamic volumes in pediatric bipolar disorder},
  journal = {American Journal of Psychiatry},
  volume = {162},
  number = {7},
  pages = {1256--1265},
  year = {2005},
  doi = {10.1176/appi.ajp.162.7.1256}
}

@article{Worsley1996,
  author = {Worsley, Keith J. and Marrett, Sean and Neelin, Peter and Vandal, Alain C. and Friston, Karl J. and Evans, Alan C.},
  title = {A unified statistical approach for determining significant signals in images of cerebral activation},
  journal = {Human Brain Mapping},
  volume = {4},
  number = {1},
  pages = {58--73},
  year = {1996},
  doi = {10.1002/(SICI)1097-0193(1996)4:1<58::AID-HBM4>3.0.CO;2-O}
}

@book{Penny2007,
  author = {Penny, William D. and Holmes, Andrew P.},
  title = {Random effects analysis},
  booktitle = {Statistical Parametric Mapping: The Analysis of Functional Brain Images},
  editor = {Friston, Karl J. and Ashburner, John T. and Kiebel, Stefan J. and Nichols, Thomas E. and Penny, William D.},
  publisher = {Academic Press},
  address = {London},
  year = {2007},
  pages = {156--165},
  chapter = {12},
  doi = {10.1016/B978-012372560-8/50012-7}
}

@article{Friston1995,
  author = {Friston, Karl J. and Holmes, Andrew P. and Worsley, Keith J. and Poline, Jean-Baptiste and Frith, Chris D. and Frackowiak, Richard S. J.},
  title = {Statistical parametric maps in functional imaging: A general linear approach},
  journal = {Human Brain Mapping},
  volume = {2},
  number = {4},
  pages = {189--210},
  year = {1995},
  doi = {10.1002/hbm.460020402}
}

@book{Fukuyama2016,
    title    = "fMRI - 原理と実践 -",
    author   = "Scott, A. Huetel and Allen, W. Song and Gregory, McCarthy",
    translate   = "秀直 福山",
    publisher = "メディカル・サイエンス・インターナショナル",
    year     = {2016},
    address  = "東京",
    isbn     = "978-4-89592-854-0",
    note     = "原著: Functional Magnetic Resonance Imaging, 3rd Edition"
  }

@ARTICLE{Esteban2018-xz,
  title    = "{fMRIPrep}: a robust preprocessing pipeline for functional {MRI}",
  author   = "Esteban, Oscar and Markiewicz, Christopher J and Blair, Ross W
              and Moodie, Craig A and Isik, A Ilkay and Erramuzpe, Asier and
              Kent, James D and Goncalves, Mathias and DuPre, Elizabeth and
              Snyder, Madeleine and Oya, Hiroyuki and Ghosh, Satrajit S and
              Wright, Jessey and Durnez, Joke and Poldrack, Russell A and
              Gorgolewski, Krzysztof J",
  abstract = "Preprocessing of functional magnetic resonance imaging (fMRI)
              involves numerous steps to clean and standardize the data before
              statistical analysis. Generally, researchers create ad hoc
              preprocessing workflows for each dataset, building upon a large
              inventory of available tools. The complexity of these workflows
              has snowballed with rapid advances in acquisition and processing.
              We introduce fMRIPrep, an analysis-agnostic tool that addresses
              the challenge of robust and reproducible preprocessing for fMRI
              data. fMRIPrep automatically adapts a best-in-breed workflow to
              the idiosyncrasies of virtually any dataset, ensuring
              high-quality preprocessing without manual intervention. By
              introducing visual assessment checkpoints into an iterative
              integration framework for software testing, we show that fMRIPrep
              robustly produces high-quality results on a diverse fMRI data
              collection. Additionally, fMRIPrep introduces less uncontrolled
              spatial smoothness than observed with commonly used preprocessing
              tools. fMRIPrep equips neuroscientists with an easy-to-use and
              transparent preprocessing workflow, which can help ensure the
              validity of inference and the interpretability of results.",
  journal  = "Nat Methods",
  volume   =  16,
  number   =  1,
  pages    = "111--116",
  month    =  dec,
  year     =  {2018},
  address  = "United States",
  language = "en"
}


@inproceedings{Radford2021,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021}
}

@Article{Lahner2024,
author={Lahner, Benjamin
and Dwivedi, Kshitij
and Iamshchinina, Polina
and Graumann, Monika
and Lascelles, Alex
and Roig, Gemma
and Gifford, Alessandro Thomas
and Pan, Bowen
and Jin, SouYoung
and Ratan Murty, N. Apurva
and Kay, Kendrick
and Oliva, Aude
and Cichy, Radoslaw},
title={Modeling short visual events through the BOLD moments video fMRI dataset and metadata},
journal={Nature Communications},
year={2024},
month={Jul},
day={24},
volume={15},
number={1},
pages={6241},
abstract={Studying the neural basis of human dynamic visual perception requires extensive experimental data to evaluate the large swathes of functionally diverse brain neural networks driven by perceiving visual events. Here, we introduce the BOLD Moments Dataset (BMD), a repository of whole-brain fMRI responses to over 1000 short (3{\thinspace}s) naturalistic video clips of visual events across ten human subjects. We use the videos' extensive metadata to show how the brain represents word- and sentence-level descriptions of visual events and identify correlates of video memorability scores extending into the parietal cortex. Furthermore, we reveal a match in hierarchical processing between cortical regions of interest and video-computable deep neural networks, and we showcase that BMD successfully captures temporal dynamics of visual events at second resolution. With its rich metadata, BMD offers new perspectives and accelerates research on the human brain basis of visual event perception.},
issn={2041-1723},
doi={10.1038/s41467-024-50310-3},
url={https://doi.org/10.1038/s41467-024-50310-3}
}



@Article{Doerig2025,
author={Doerig, Adrien
and Kietzmann, Tim C.
and Allen, Emily
and Wu, Yihan
and Naselaris, Thomas
and Kay, Kendrick
and Charest, Ian},
title={High-level visual representations in the human brain are aligned with large language models},
journal={Nature Machine Intelligence},
year={2025},
month={Aug},
day={01},
volume={7},
number={8},
pages={1220-1234},
abstract={The human brain extracts complex information from visual inputs, including objects, their spatial and semantic interrelations, and their interactions with the environment. However, a quantitative approach for studying this information remains elusive. Here we test whether the contextual information encoded in large language models (LLMs) is beneficial for modelling the complex visual information extracted by the brain from natural scenes. We show that LLM embeddings of scene captions successfully characterize brain activity evoked by viewing the natural scenes. This mapping captures selectivities of different brain areas and is sufficiently robust that accurate scene captions can be reconstructed from brain activity. Using carefully controlled model comparisons, we then proceed to show that the accuracy with which LLM representations match brain representations derives from the ability of LLMs to integrate complex information contained in scene captions beyond that conveyed by individual words. Finally, we train deep neural network models to transform image inputs into LLM representations. Remarkably, these networks learn representations that are better aligned with brain representations than a large number of state-of-the-art alternative models, despite being trained on orders-of-magnitude less data. Overall, our results suggest that LLM embeddings of scene captions provide a representational format that accounts for complex information extracted by the brain from visual inputs.},
issn={2522-5839},
doi={10.1038/s42256-025-01072-0},
url={https://doi.org/10.1038/s42256-025-01072-0}
}



@Article{Richards2019,
author={Richards, Blake A.
and Lillicrap, Timothy P.
and Beaudoin, Philippe
and Bengio, Yoshua
and Bogacz, Rafal
and Christensen, Amelia
and Clopath, Claudia
and Costa, Rui Ponte
and de Berker, Archy
and Ganguli, Surya
and Gillon, Colleen J.
and Hafner, Danijar
and Kepecs, Adam
and Kriegeskorte, Nikolaus
and Latham, Peter
and Lindsay, Grace W.
and Miller, Kenneth D.
and Naud, Richard
and Pack, Christopher C.
and Poirazi, Panayiota
and Roelfsema, Pieter
and Sacramento, Jo{\~a}o
and Saxe, Andrew
and Scellier, Benjamin
and Schapiro, Anna C.
and Senn, Walter
and Wayne, Greg
and Yamins, Daniel
and Zenke, Friedemann
and Zylberberg, Joel
and Therien, Denis
and Kording, Konrad P.},
title={A deep learning framework for neuroscience},
journal={Nature Neuroscience},
year={2019},
month={Nov},
day={01},
volume={22},
number={11},
pages={1761-1770},
abstract={Systems neuroscience seeks explanations for how the brain implements a wide variety of perceptual, cognitive and motor tasks. Conversely, artificial intelligence attempts to design computational systems based on the tasks they will have to solve. In artificial neural networks, the three components specified by design are the objective functions, the learning rules and the architectures. With the growing success of deep learning, which utilizes brain-inspired architectures, these three designed components have increasingly become central to how we model, engineer and optimize complex artificial learning systems. Here we argue that a greater focus on these components would also benefit systems neuroscience. We give examples of how this optimization-based framework can drive theoretical and experimental progress in neuroscience. We contend that this principled perspective on systems neuroscience will help to generate more rapid progress.},
issn={1546-1726},
doi={10.1038/s41593-019-0520-2},
url={https://doi.org/10.1038/s41593-019-0520-2}
}


@Article{Kriegeskorte2018,
author={Kriegeskorte, Nikolaus
and Douglas, Pamela K.},
title={Cognitive computational neuroscience},
journal={Nature Neuroscience},
year={2018},
month={Sep},
day={01},
volume={21},
number={9},
pages={1148-1160},
abstract={To learn how cognition is implemented in the brain, we must build computational models that can perform cognitive tasks, and test such models with brain and behavioral experiments. Cognitive science has developed computational models that decompose cognition into functional components. Computational neuroscience has modeled how interacting neurons can implement elementary components of cognition. It is time to assemble the pieces of the puzzle of brain computation and to better integrate these separate disciplines. Modern technologies enable us to measure and manipulate brain activity in unprecedentedly rich ways in animals and humans. However, experiments will yield theoretical insight only when employed to test brain-computational models. Here we review recent work in the intersection of cognitive science, computational neuroscience and artificial intelligence. Computational models that mimic brain information processing during perceptual, cognitive and control tasks are beginning to be developed and tested with brain and behavioral data.},
issn={1546-1726},
doi={10.1038/s41593-018-0210-5},
url={https://doi.org/10.1038/s41593-018-0210-5}
}



@article{54030559-6348-39cf-abea-9a63f249f992,
 ISSN = {09567976, 14679280},
 URL = {http://www.jstor.org/stable/24543633},
 abstract = {The factors that affect food choices are critical to understanding obesity. In the present study, healthy participants were shown pictures of foods to determine the impact of caloric content on food choice. Brain activity was then measured while participants bid for a chance to purchase and eat one item. True caloric density, but not individual estimates of calorie content, predicted how much participants were willing to pay for each item. Caloric density also correlated with the neural response to food pictures in the ventromedial prefrontal cortex, a brain area that encodes the value of stimuli and predicts immediate consumption. That same region exhibited functional connectivity with an appetitive brain network, and this connectivity was modulated by willingness to pay. Despite the fact that participants were poor at explicitly judging caloric content, their willingness to pay and brain activity both correlated with actual caloric density. This suggests that the reward value of a familiar food is dependent on implicit knowledge of its caloric content.},
 author = {Deborah W. Tang and Lesley K. Fellows and Alain Dagher},
 journal = {Psychological Science},
 number = {12},
 pages = {2168--2176},
 publisher = {[Association for Psychological Science, Sage Publications, Inc.]},
 title = {Behavioral and neural valuation of foods is driven by implicit knowledge of caloric content},
 urldate = {2025-10-08},
 volume = {25},
 year = {2014}
}


@article{VADUGANATHAN20222361,
title = {The global burden of cardiovascular diseases and risk: A compass for future health},
journal = {Journal of the American College of Cardiology},
volume = {80},
number = {25},
pages = {2361-2371},
year = {2022},
issn = {0735-1097},
doi = {https://doi.org/10.1016/j.jacc.2022.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0735109722073120},
author = {Muthiah Vaduganathan and George A. Mensah and Justine Varieur Turco and Valentin Fuster and Gregory A. Roth},
keywords = {cardiovascular health, epidemiology, Global Burden of Disease Study, public health}
}

@article{Rangel2008,
  author={Rangel, Antonio
  and Camerer, Colin
  and Montague, P. Read},
  title={A framework for studying the neurobiology of value-based decision making},
  journal={Nature Reviews Neuroscience},
  year={2008},
  month={Jul},
  day={01},
  volume={9},
  number={7},
  pages={545-556},
  abstract={Most behavioural and computational models of decision making assume that the following five processes are carried out at the time the decision is made: representation, action valuation, action selection, outcome valuation, and learning.On the basis of a sizeable body of animal and human behavioural evidence, several groups have proposed the existence of three different types of valuation systems: Pavlovian, habitual and goal-directed systems.Pavlovian systems assign value to only a small set of 'prepared' behaviours and thus have a limited behavioural repertoire. Nevertheless, they might be the driving force behind behaviours with important economic consequences (for example, overeating). Examples include preparatory behaviours, such as approaching a cue that predicts food, and consummatory behaviours, such as ingesting available food.Habit valuation systems learn to assign values to stimulus--response associations on the basis of previous experience through a process of trial-and-error. Examples of habits include a smoker's desire to have a cigarette at particular times of day (for example, after a meal) and a rat's tendency to forage in a cue-dependent location after sufficient training.Goal-directed systems assign values to actions by computing action--outcome associations and then evaluating the rewards that are associated with the different outcomes. An example of a goal-directed behaviour is the decision what to eat at a new restaurant.An important difference between habitual and goal-directed systems has to do with how they respond to changes in the environment. The goal-directed system updates the value of an action as soon as the value of its outcome changes, whereas the habit system only learns with repeated experience.The values computed by the three systems can be modulated by factors such as the risk that is associated with the decision, the time delay to the outcomes, and social considerations.The quality of the decisions made by an animal depend on how its brain assigns control to the different valuation systems in situations in which it has to make a choice between several potential actions that are assigned conflicting values.The learning properties of the habit system seem to be well-described by simple reinforcement algorithms, such as Q-learning. Some of the key computations that are predicted by these models are instantiated in the dopamine system.},
  issn={1471-0048},
  doi={10.1038/nrn2357},
  url={https://doi.org/10.1038/nrn2357}
}

@article{Foerde2015,
  author={Foerde, Karin
  and Steinglass, Joanna E.
  and Shohamy, Daphna
  and Walsh, B. Timothy},
  title={Neural mechanisms supporting maladaptive food choices in anorexia nervosa},
  journal={Nature Neuroscience},
  year={2015},
  month={Nov},
  day={01},
  volume={18},
  number={11},
  pages={1571-1573},
  abstract={Anorexia nervosa provides a compelling example of persistent maladaptive behavior: the severe restriction of caloric intake. Activity in the dorsal striatum was greater in patients than in controls during food choice and correlated with subsequent caloric intake, suggesting that dorsal fronto-striatal circuits are involved in this disorder.},
  issn={1546-1726},
  doi={10.1038/nn.4136},
  url={https://doi.org/10.1038/nn.4136}
}

@article{Spinelli2021-yi,
  title    = "Food Preferences and Obesity",
  author   = "Spinelli, Sara and Monteleone, Erminio",
  abstract = "Obesity is a multifactorial disease with several potential causes
              that remain incompletely understood. Recent changes in the
              environment, which has become increasingly obesogenic, have been
              found to interact with individual factors. Evidence of the role
              of taste responsiveness and food preference in obesity has been
              reported, pointing to a lower taste sensitivity and a higher
              preference and intake of fat and, to a lesser extent, sweet foods
              in obese people. Studies in the last decades have also suggested
              that individual differences in the neurophysiology of food reward
              may lead to overeating, contributing to obesity. However, further
              studies are needed to confirm these findings. In fact, only a
              limited number of studies has been conducted on large samples,
              and several studies were conducted only on women. Larger balanced
              studies in terms of sex/gender and age are required in order to
              control the confounding effect of these variables. As many
              factors are intertwined in obesity, a multidisciplinary approach
              is needed. This will allow a better understanding of taste
              alteration and food behaviours in obese people in order to design
              more effective strategies to promote healthier eating and to
              prevent obesity and the related chronic disease risks.",
  journal  = "Endocrinol Metab (Seoul)",
  volume   =  36,
  number   =  2,
  pages    = "209--219",
  month    =  apr,
  year     =  2021,
  address  = "Korea (South)",
  keywords = "Body mass index; Food preferences; Obesity; Propylthiouracil;
              Reward; Taste",
  language = "en"
}

@article{Hare2009,
  author = {Hare, Todd A. and Camerer, Colin F. and Rangel, Antonio},
  title = {Self-control in decision-making involves modulation of the vmPFC valuation system},
  journal = {Science},
  year = {2009},
  volume = {324},
  number = {5927},
  pages = {646-648},
  doi = {10.1126/science.1168450},
  url = {https://www.science.org/doi/abs/10.1126/science.1168450}
}

@article{Suzuki2017-wk,
  title    = "Elucidating the underlying components of food valuation in the
              human orbitofrontal cortex",
  author   = "Suzuki, Shinsuke and Cross, Logan and O'Doherty, John P",
  abstract = "The valuation of food is a fundamental component of our
              decision-making. Yet little is known about how value signals for
              food and other rewards are constructed by the brain. Using a
              food-based decision task in human participants, we found that
              subjective values can be predicted from beliefs about constituent
              nutritive attributes of food: protein, fat, carbohydrates and
              vitamin content. Multivariate analyses of functional MRI data
              demonstrated that, while food value is represented in patterns of
              neural activity in both medial and lateral parts of the
              orbitofrontal cortex (OFC), only the lateral OFC represents the
              elemental nutritive attributes. Effective connectivity analyses
              further indicate that information about the nutritive attributes
              represented in the lateral OFC is integrated within the medial
              OFC to compute an overall value. These findings provide a
              mechanistic account for the construction of food value from its
              constituent nutrients.",
  journal  = "Nat Neurosci",
  volume   =  20,
  number   =  12,
  pages    = "1780--1786",
  month    =  oct,
  year     =  2017,
  address  = "United States",
  language = "en"
}

@article{Motoki2020-lf,
  title    = "Extrinsic Factors Underlying Food Valuation in the Human Brain",
  author   = "Motoki, Kosuke and Suzuki, Shinsuke",
  abstract = "Subjective values for food rewards guide our dietary choices.
              There is growing evidence that value signals are constructed in
              the brain by integrating multiple types of information about
              flavor, taste, and nutritional attributes of the foods. However,
              much less is known about the influence of food-extrinsic factors
              such as labels, brands, prices, and packaging designs. In this
              mini-review article, we outline recent findings in decision
              neuroscience, consumer psychology, and food science about the
              effect of extrinsic factors on food value computations in the
              human brain. To date, studies have demonstrated that, while the
              integrated value signal is encoded in the ventromedial prefrontal
              cortex, information on the extrinsic factors of the food is
              encoded in diverse brain regions previously implicated in a wide
              range of functions: cognitive control, memory, emotion and reward
              processing. We suggest that a comprehensive understanding of food
              valuation requires elucidation of the mechanisms behind
              integrating extrinsic factors in the brain to compute an overall
              subjective value signal.",
  journal  = "Front Behav Neurosci",
  volume   =  14,
  pages    = "131",
  month    =  jul,
  year     =  2020,
  address  = "Switzerland",
  keywords = "consumer psychology; decision-making; fMRI; food; preference;
              reward; value",
  language = "en"
}

@article{Chib2009-jq,
  title    = "Evidence for a common representation of decision values for
              dissimilar goods in human ventromedial prefrontal cortex",
  author   = "Chib, Vikram S and Rangel, Antonio and Shimojo, Shinsuke and
              O'Doherty, John P",
  abstract = "To make economic choices between goods, the brain needs to
              compute representations of their values. A great deal of research
              has been performed to determine the neural correlates of value
              representations in the human brain. However, it is still unknown
              whether there exists a region of the brain that commonly encodes
              decision values for different types of goods, or if, in contrast,
              the values of different types of goods are represented in
              distinct brain regions. We addressed this question by scanning
              subjects with functional magnetic resonance imaging while they
              made real purchasing decisions among different categories of
              goods (food, nonfood consumables, and monetary gambles). We found
              activity in a key brain region previously implicated in encoding
              goal-values: the ventromedial prefrontal cortex (vmPFC) was
              correlated with the subjects' value for each category of good.
              Moreover, we found a single area in vmPFC to be correlated with
              the subjects' valuations for all categories of goods. Our results
              provide evidence that the brain encodes a ``common currency''
              that allows for a shared valuation for different categories of
              goods.",
  journal  = "J Neurosci",
  volume   =  29,
  number   =  39,
  pages    = "12315--12320",
  month    =  sep,
  year     =  2009,
  address  = "United States",
  language = "en"
}


@article{10.3389/fpsyg.2014.00617,

  AUTHOR={Blechert, Jens  and Meule, Adrian  and Busch, Niko A.  and Ohla, Kathrin },

  TITLE={Food-pics: an image database for experimental research on eating and appetite},

  JOURNAL={Frontiers in Psychology},

  VOLUME={5},

  YEAR={2014},

  URL={https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2014.00617},

  DOI={10.3389/fpsyg.2014.00617},

  ISSN={1664-1078},

  ABSTRACT={<p>Our current environment is characterized by the omnipresence of food cues. The sight and smell of real foods, but also graphically depictions of appetizing foods, can guide our eating behavior, for example, by eliciting food craving and influencing food choice. The relevance of visual food cues on human information processing has been demonstrated by a growing body of studies employing food images across the disciplines of psychology, medicine, and neuroscience. However, currently used food image sets vary considerably across laboratories and image characteristics (contrast, brightness, etc.) and food composition (calories, macronutrients, etc.) are often unspecified. These factors might have contributed to some of the inconsistencies of this research. To remedy this, we developed <italic>food-pics</italic>, a picture database comprising 568 food images and 315 non-food images along with detailed meta-data. A total of <italic>N</italic> = 1988 individuals with large variance in age and weight from German speaking countries and North America provided normative ratings of valence, arousal, palatability, desire to eat, recognizability and visual complexity. Furthermore, data on macronutrients (g), energy density (kcal), and physical image characteristics (color composition, contrast, brightness, size, complexity) are provided. The <italic>food-pics</italic> image database is freely available under the creative commons license with the hope that the set will facilitate standardization and comparability across studies and advance experimental research on the determinants of eating behavior.</p>}
}

@article{foodpics2014,
  author={Blechert, Jens and Meule, Adrian and Busch, Niko A. and Ohla, Kathrin},
  title={Food-pics: an image database for experimental research on eating and appetite},
  journal={Frontiers in Psychology},
  volume={5},
  year={2014},
  doi={10.3389/fpsyg.2014.00617},
  url={https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2014.00617}
}


@article{10.3389/fpsyg.2019.00307,

AUTHOR={Blechert, Jens  and Lender, Anja  and Polk, Sarah  and Busch, Niko A.  and Ohla, Kathrin },

TITLE={Food-Pics\_Extended—An Image Database for Experimental Research on Eating and Appetite: Additional Images, Normative Ratings and an Updated Review},

JOURNAL={Frontiers in Psychology},

VOLUME={10},

YEAR={2019},

URL={https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2019.00307},

DOI={10.3389/fpsyg.2019.00307},

ISSN={1664-1078},

ABSTRACT={<p>Our current environment is characterized by the omnipresence of food cues. The taste and smell of real foods—but also graphical depictions of appetizing foods—can guide our eating behavior, for example, by eliciting food craving and anticipatory cephalic phase responses. To facilitate research into this so-called cue reactivity, several groups have compiled standardized food image sets. Yet, selecting the best subset of images for a specific research question can be difficult as images and image sets vary along several dimensions. In the present report, we review the strengths and weaknesses of popular food image sets to guide researchers during stimulus selection. Furthermore, we present a recent extension of our previously published database <italic>food-pics</italic>, which comprises an additional 328 food images from different countries to increase cross-cultural applicability. This <italic>food-pics\_extended</italic> stimulus database, thus, encompasses and replaces <italic>food-pics</italic>. Normative data from a predominantly German-speaking sample are again presented as well as updated calculations of image characteristics.</p>}}


@article{Yamins2014-it,
  title    = "Performance-optimized hierarchical models predict neural
              responses in higher visual cortex",
  author   = "Yamins, Daniel L K and Hong, Ha and Cadieu, Charles F and
              Solomon, Ethan A and Seibert, Darren and DiCarlo, James J",
  abstract = "The ventral visual stream underlies key human visual object
              recognition abilities. However, neural encoding in the higher
              areas of the ventral stream remains poorly understood. Here, we
              describe a modeling approach that yields a quantitatively
              accurate model of inferior temporal (IT) cortex, the highest
              ventral cortical area. Using high-throughput computational
              techniques, we discovered that, within a class of biologically
              plausible hierarchical neural network models, there is a strong
              correlation between a model's categorization performance and its
              ability to predict individual IT neural unit response data. To
              pursue this idea, we then identified a high-performing neural
              network that matches human performance on a range of recognition
              tasks. Critically, even though we did not constrain this model to
              match neural data, its top output layer turns out to be highly
              predictive of IT spiking responses to complex naturalistic images
              at both the single site and population levels. Moreover, the
              model's intermediate layers are highly predictive of neural
              responses in the V4 cortex, a midlevel visual area that provides
              the dominant cortical input to IT. These results show that
              performance optimization--applied in a biologically appropriate
              model class--can be used to build quantitative predictive models
              of neural processing.",
  journal  = "Proc Natl Acad Sci U S A",
  volume   =  111,
  number   =  23,
  pages    = "8619--8624",
  month    =  may,
  year     =  2014,
  address  = "United States",
  keywords = "array electrophysiology; computational neuroscience; computer
              vision",
  language = "en"
}

@article{foodpics2019,
  author={Blechert, Jens and Lender, Anja and Polk, Sarah and Busch, Niko A. and Ohla, Kathrin},
  title={Food-Pics_Extended—An Image Database for Experimental Research on Eating and Appetite: Additional Images, Normative Ratings and an Updated Review},
  journal={Frontiers in Psychology},
  volume={10},
  year={2019},
  doi={10.3389/fpsyg.2019.00307},
  url={https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2019.00307}
}


@article{Iigaya2023,
author={Iigaya, Kiyohito
and Yi, Sanghyun
and Wahle, Iman A.
and Tanwisuth, Sandy
and Cross, Logan
and O'Doherty, John P.},
title={Neural mechanisms underlying the hierarchical construction of perceived aesthetic value},
journal={Nature Communications},
year={2023},
month={Jan},
day={24},
volume={14},
number={1},
pages={127},
abstract={Little is known about how the brain computes the perceived aesthetic value of complex stimuli such as visual art. Here, we used computational methods in combination with functional neuroimaging to provide evidence that the aesthetic value of a visual stimulus is computed in a hierarchical manner via a weighted integration over both low and high level stimulus features contained in early and late visual cortex, extending into parietal and lateral prefrontal cortices. Feature representations in parietal and lateral prefrontal cortex may in turn be utilized to produce an overall aesthetic value in the medial prefrontal cortex. Such brain-wide computations are not only consistent with a feature-based mechanism for value construction, but also resemble computations performed by a deep convolutional neural network. Our findings thus shed light on the existence of a general neurocomputational mechanism for rapidly and flexibly producing value judgements across an array of complex novel stimuli and situations.},
issn={2041-1723},
doi={10.1038/s41467-022-35654-y},
url={https://doi.org/10.1038/s41467-022-35654-y}
}


@article{Iigaya2021,
  author={Iigaya, Kiyohito
  and Yi, Sanghyun
  and Wahle, Iman A.
  and Tanwisuth, Koranis
  and O'Doherty, John P.},
  title={Aesthetic preference for art can be predicted from a mixture of low- and high-level visual features},
  journal={Nature Human Behaviour},
  year={2021},
  month={Jun},
  day={01},
  volume={5},
  number={6},
  pages={743-755},
  abstract={It is an open question whether preferences for visual art can be lawfully predicted from the basic constituent elements of a visual image. Here, we developed and tested a computational framework to investigate how aesthetic values are formed. We show that it is possible to explain human preferences for a visual art piece based on a mixture of low- and high-level features of the image. Subjective value ratings could be predicted not only within but also across individuals, using a regression model with a common set of interpretable features. We also show that the features predicting aesthetic preference can emerge hierarchically within a deep convolutional neural network trained only for object recognition. Our findings suggest that human preferences for art can be explained at least in part as a systematic integration over the underlying visual features of an image.},
  issn={2397-3374},
  doi={10.1038/s41562-021-01124-6},
  url={https://doi.org/10.1038/s41562-021-01124-6}
}


@inproceedings{liu2022convnet2020s,
  title={A ConvNet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11976--11986},
  year={2022}
}

@inproceedings{he2015,
  title={Deep Residual Learning for Image Recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{simonyan2015,
  title={Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@Article{Bowers2023,
author={Bowers, Jeffrey S.
and Malhotra, Gaurav
and Dujmovi{\'{c}}, Marin
and Llera Montero, Milton
and Tsvetkov, Christian
and Biscione, Valerio
and Puebla, Guillermo
and Adolfi, Federico
and Hummel, John E.
and Heaton, Rachel F.
and Evans, Benjamin D.
and Mitchell, Jeffrey
and Blything, Ryan},
title={Deep problems with neural network models of human vision},
journal={Behavioral and Brain Sciences},
year={2023},
edition={2022/12/01},
publisher={Cambridge University Press},
volume={46},
pages={e385},
keywords={Brain-Score; computational neuroscience; deep neural networks; human vision; object recognition},
abstract={Deep neural networks (DNNs) have had extraordinary successes in classifying photographic images of objects and are often described as the best models of biological vision. This conclusion is largely based on three sets of findings: (1) DNNs are more accurate than any other model in classifying images taken from various datasets, (2) DNNs do the best job in predicting the pattern of human errors in classifying objects taken from various behavioral datasets, and (3) DNNs do the best job in predicting brain signals in response to images taken from various brain datasets (e.g., single cell responses or fMRI data). However, these behavioral and brain datasets do not test hypotheses regarding what features are contributing to good predictions and we show that the predictions may be mediated by DNNs that share little overlap with biological vision. More problematically, we show that DNNs account for almost no results from psychological research. This contradicts the common claim that DNNs are good, let alone the best, models of human object recognition. We argue that theorists interested in developing biologically plausible models of human vision need to direct their attention to explaining psychological findings. More generally, theorists need to build models that explain the results of experiments that manipulate independent variables designed to test hypotheses rather than compete on making the best predictions. We conclude by briefly summarizing various promising modeling approaches that focus on psychological data.},
note={e385},
issn={0140-525X},
doi={10.1017/S0140525X22002813},
url={https://www.cambridge.org/core/product/ABCE483EE95E80315058BB262DCA26A9},
url={https://doi.org/10.1017/S0140525X22002813}
}


@article{Caplette2024,
  author={Caplette, Laurent
  and Turk-Browne, Nicholas B.},
  title={Computational reconstruction of mental representations using human behavior},
  journal={Nature Communications},
  year={2024},
  month={May},
  day={17},
  volume={15},
  number={1},
  pages={4183},
  abstract={Revealing how the mind represents information is a longstanding goal of cognitive science. However, there is currently no framework for reconstructing the broad range of mental representations that humans possess. Here, we ask participants to indicate what they perceive in images made of random visual features in a deep neural network. We then infer associations between the semantic features of their responses and the visual features of the images. This allows us to reconstruct the mental representations of multiple visual concepts, both those supplied by participants and other concepts extrapolated from the same semantic space. We validate these reconstructions in separate participants and further generalize our approach to predict behavior for new stimuli and in a new task. Finally, we reconstruct the mental representations of individual observers and of a neural network. This framework enables a large-scale investigation of conceptual representations.},
  issn={2041-1723},
  doi={10.1038/s41467-024-48114-6},
  url={https://doi.org/10.1038/s41467-024-48114-6}
}

@article{
Glimcher2004,
author = {Paul W. Glimcher  and Aldo Rustichini },
title = {Neuroeconomics: The Consilience of Brain and Decision},
journal = {Science},
volume = {306},
number = {5695},
pages = {447-452},
year = {2004},
doi = {10.1126/science.1102566},
URL = {https://www.science.org/doi/abs/10.1126/science.1102566},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1102566},
abstract = {Economics, psychology, and neuroscience are converging today into a single, unified discipline with the ultimate aim of providing a single, general theory of human behavior. This is the emerging field of neuroeconomics in which consilience, the accordance of two or more inductions drawn from different groups of phenomena, seems to be operating. Economists and psychologists are providing rich conceptual tools for understanding and modeling behavior, while neurobiologists provide tools for the study of mechanism. The goal of this discipline is thus to understand the processes that connect sensation and action by revealing the neurobiological mechanisms by which decisions are made. This review describes recent developments in neuroeconomics from both behavioral and biological perspectives.}}



// related work
@article {Levy118,
author = {Levy, Ifat and Lazzaro, Stephanie C. and Rutledge, Robb B. and Glimcher, Paul W.},
title = {Choice from non-choice: Predicting consumer preferences from blood oxygenation level-dependent signals obtained during passive viewing},
volume = {31},
number = {1},
pages = {118--125},
year = {2011},
doi = {10.1523/JNEUROSCI.3214-10.2011},
publisher = {Society for Neuroscience},
abstract = {Decision-making is often viewed as a two-stage process, where subjective values are first assigned to each option and then the option of the highest value is selected. Converging evidence suggests that these subjective values are represented in the striatum and medial prefrontal cortex (MPFC). A separate line of evidence suggests that activation in the same areas represents the values of rewards even when choice is not required, as in classical conditioning tasks. However, it is unclear whether the same neural mechanism is engaged in both cases. To address this question we measured brain activation with functional magnetic resonance imaging while human subjects passively viewed individual consumer goods. We then sampled activation from predefined regions of interest and used it to predict subsequent choices between the same items made outside of the scanner. Our results show that activation in the striatum and MPFC in the absence of choice predicts subsequent choices, suggesting that these brain areas represent value in a similar manner whether or not choice is required.},
issn = {0270-6474},
URL = {https://www.jneurosci.org/content/31/1/118},
eprint = {https://www.jneurosci.org/content/31/1/118.full.pdf},
journal = {Journal of Neuroscience}
}

@article {Hare5623,
author = {Hare, Todd A. and O{\textquoteright}Doherty, John and Camerer, Colin F. and Schultz, Wolfram and Rangel, Antonio},
title = {Dissociating the role of the orbitofrontal cortex and the striatum in the computation of goal values and prediction errors},
volume = {28},
number = {22},
pages = {5623--5630},
year = {2008},
doi = {10.1523/JNEUROSCI.1309-08.2008},
publisher = {Society for Neuroscience},
abstract = {To make sound economic decisions, the brain needs to compute several different value-related signals. These include goal values that measure the predicted reward that results from the outcome generated by each of the actions under consideration, decision values that measure the net value of taking the different actions, and prediction errors that measure deviations from individuals{\textquoteright} previous reward expectations. We used functional magnetic resonance imaging and a novel decision-making paradigm to dissociate the neural basis of these three computations. Our results show that they are supported by different neural substrates: goal values are correlated with activity in the medial orbitofrontal cortex, decision values are correlated with activity in the central orbitofrontal cortex, and prediction errors are correlated with activity in the ventral striatum.},
issn = {0270-6474},
URL = {https://www.jneurosci.org/content/28/22/5623},
eprint = {https://www.jneurosci.org/content/28/22/5623.full.pdf},
journal = {Journal of Neuroscience}
}

@article{
Samejima2005,
author = {Kazuyuki Samejima  and Yasumasa Ueda  and Kenji Doya  and Minoru Kimura },
title = {Representation of action-specific reward values in the striatum},
journal = {Science},
volume = {310},
number = {5752},
pages = {1337-1340},
year = {2005},
doi = {10.1126/science.1115270},
URL = {https://www.science.org/doi/abs/10.1126/science.1115270},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1115270},
abstract = {The estimation of the reward an action will yield is critical in decision-making. To elucidate the role of the basal ganglia in this process, we recorded striatal neurons of monkeys who chose between left and right handle turns, based on the estimated reward probabilities of the actions. During a delay period before the choices, the activity of more than one-third of striatal projection neurons was selective to the values of one of the two actions. Fewer neurons were tuned to relative values or action choice. These results suggest representation of action values in the striatum, which can guide action selection in the basal ganglia circuit.}}

@article {Gross7580,
author = {Gross, J{\"o}rg and Woelbert, Eva and Zimmermann, Jan and Okamoto-Barth, Sanae and Riedl, Arno and Goebel, Rainer},
title = {Value signals in the prefrontal cortex predict individual preferences across reward categories},
volume = {34},
number = {22},
pages = {7580--7586},
year = {2014},
doi = {10.1523/JNEUROSCI.5082-13.2014},
publisher = {Society for Neuroscience},
abstract = {Humans can choose between fundamentally different options, such as watching a movie or going out for dinner. According to the utility concept, put forward by utilitarian philosophers and widely used in economics, this may be accomplished by mapping the value of different options onto a common scale, independent of specific option characteristics (Fehr and Rangel, 2011; Levy and Glimcher, 2012). If this is the case, value-related activity patterns in the brain should allow predictions of individual preferences across fundamentally different reward categories. We analyze fMRI data of the prefrontal cortex while subjects imagine the pleasure they would derive from items belonging to two distinct reward categories: engaging activities (like going out for drinks, daydreaming, or doing sports) and snack foods. Support vector machines trained on brain patterns related to one category reliably predict individual preferences of the other category and vice versa. Further, we predict preferences across participants. These findings demonstrate that prefrontal cortex value signals follow a common scale representation of value that is even comparable across individuals and could, in principle, be used to predict choice.},
issn = {0270-6474},
URL = {https://www.jneurosci.org/content/34/22/7580},
eprint = {https://www.jneurosci.org/content/34/22/7580.full.pdf},
journal = {Journal of Neuroscience}
}

@article {Hampton8360,
author = {Hampton, Alan N. and Bossaerts, Peter and O{\textquoteright}Doherty, John P.},
title = {The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans},
volume = {26},
number = {32},
pages = {8360--8367},
year = {2006},
doi = {10.1523/JNEUROSCI.1010-06.2006},
publisher = {Society for Neuroscience},
abstract = {Many real-life decision-making problems incorporate higher-order structure, involving interdependencies between different stimuli, actions, and subsequent rewards. It is not known whether brain regions implicated in decision making, such as the ventromedial prefrontal cortex (vmPFC), use a stored model of the task structure to guide choice (model-based decision making) or merely learn action or state values without assuming higher-order structure as in standard reinforcement learning. To discriminate between these possibilities, we scanned human subjects with functional magnetic resonance imaging while they performed a simple decision-making task with higher-order structure, probabilistic reversal learning. We found that neural activity in a key decision-making region, the vmPFC, was more consistent with a computational model that exploits higher-order structure than with simple reinforcement learning. These results suggest that brain regions, such as the vmPFC, use an abstract model of task structure to guide behavioral choice, computations that may underlie the human capacity for complex social interactions and abstract strategizing.},
issn = {0270-6474},
URL = {https://www.jneurosci.org/content/26/32/8360},
eprint = {https://www.jneurosci.org/content/26/32/8360.full.pdf},
journal = {Journal of Neuroscience}
}

@article{
Rutledge2014,
author = {Robb B. Rutledge  and Nikolina Skandali  and Peter Dayan  and Raymond J. Dolan },
title = {A computational and neural model of momentary subjective well-being},
journal = {Proceedings of the National Academy of Sciences},
volume = {111},
number = {33},
pages = {12252-12257},
year = {2014},
doi = {10.1073/pnas.1407535111},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1407535111},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1407535111},
abstract = {A common question in the social science of well-being asks, “How happy do you feel on a scale of 0 to 10?” Responses are often related to life circumstances, including wealth. By asking people about their feelings as they go about their lives, ongoing happiness and life events have been linked, but the neural mechanisms underlying this relationship are unknown. To investigate it, we presented subjects with a decision-making task involving monetary gains and losses and repeatedly asked them to report their momentary happiness. We built a computational model in which happiness reports were construed as an emotional reactivity to recent rewards and expectations. Using functional MRI, we demonstrated that neural signals during task events account for changes in happiness. The subjective well-being or happiness of individuals is an important metric for societies. Although happiness is influenced by life circumstances and population demographics such as wealth, we know little about how the cumulative influence of daily life events are aggregated into subjective feelings. Using computational modeling, we show that emotional reactivity in the form of momentary happiness in response to outcomes of a probabilistic reward task is explained not by current task earnings, but by the combined influence of recent reward expectations and prediction errors arising from those expectations. The robustness of this account was evident in a large-scale replication involving 18,420 participants. Using functional MRI, we show that the very same influences account for task-dependent striatal activity in a manner akin to the influences underpinning changes in happiness.}}


@ARTICLE{Suzuki2015-ey,
title    = "Neural mechanisms underlying human consensus decision-making",
author   = "Suzuki, Shinsuke and Adachi, Ryo and Dunne, Simon and Bossaerts,
Peter and O'Doherty, John P",
abstract = "Consensus building in a group is a hallmark of animal societies,
yet little is known about its underlying computational and neural
mechanisms. Here, we applied a computational framework to
behavioral and fMRI data from human participants performing a
consensus decision-making task with up to five other
participants. We found that participants reached consensus
decisions through integrating their own preferences with
information about the majority group members' prior choices, as
well as inferences about how much each option was stuck to by the
other people. These distinct decision variables were separately
encoded in distinct brain areas-the ventromedial prefrontal
cortex, posterior superior temporal sulcus/temporoparietal
junction, and intraparietal sulcus-and were integrated in the
dorsal anterior cingulate cortex. Our findings provide support
for a theoretical account in which collective decisions are made
through integrating multiple types of inference about oneself,
others, and environments, processed in distinct brain modules.",
journal  = "Neuron",
volume   =  86,
number   =  2,
pages    = "591--602",
month    =  apr,
year     =  2015,
address  = "United States",
language = "en"
}


@article{Kriegeskorte2015,
   author = "Kriegeskorte, Nikolaus",
   title = "Deep neural networks: A new framework for modeling biological vision and brain information processing",
   journal= "Annual Review of Vision Science",
   year = "2015",
   volume = "1",
   number = "Volume 1, 2015",
   pages = "417-446",
   doi = "https://doi.org/10.1146/annurev-vision-082114-035447",
   url = "https://www.annualreviews.org/content/journals/10.1146/annurev-vision-082114-035447",
   publisher = "Annual Reviews",
   issn = "2374-4650",
   type = "Journal Article",
   keywords = "object recognition",
   keywords = "neural network",
   keywords = "biological vision",
   keywords = "computer vision",
   keywords = "artificial intelligence",
   keywords = "computational neuroscience",
   keywords = "deep learning",
   abstract = "Recent advances in neural network modeling have enabled major strides in computer vision and other artificial intelligence applications. Human-level visual recognition abilities are coming within reach of artificial systems. Artificial neural networks are inspired by the brain, and their computations could be implemented in biological neurons. Convolutional feedforward networks, which now dominate computer vision, take further inspiration from the architecture of the primate visual hierarchy. However, the current models are designed with engineering goals, not to model brain computations. Nevertheless, initial studies comparing internal representations between these models and primate brains find surprisingly similar representational spaces. With human-level performance no longer out of reach, we are entering an exciting new era, in which we will be able to build biologically faithful feedforward and recurrent computational models of how biological brains perform high-level feats of intelligence, including vision.",
  }


@INPROCEEDINGS{Deng2009,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
  title={ImageNet: A large-scale hierarchical image database},
  year={2009},
  volume={},
  number={},
  pages={248-255},
  keywords={Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  doi={10.1109/CVPR.2009.5206848}}

@inproceedings{Krizhevsky2012,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet classification with deep convolutional neural networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@inproceedings{Vaswani2017,
  title={Attention Is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{Brown2020,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{openai2023,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2024}
}

@article{
Schrimpf2021,
author = {Martin Schrimpf  and Idan Asher Blank  and Greta Tuckute  and Carina Kauf  and Eghbal A. Hosseini  and Nancy Kanwisher  and Joshua B. Tenenbaum  and Evelina Fedorenko },
title = {The neural architecture of language: Integrative modeling converges on predictive processing},
journal = {Proceedings of the National Academy of Sciences},
volume = {118},
number = {45},
pages = {e2105646118},
year = {2021},
doi = {10.1073/pnas.2105646118},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2105646118},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2105646118},
abstract = {Language is a quintessentially human ability. Research has long probed the functional architecture of language in the mind and brain using diverse neuroimaging, behavioral, and computational modeling approaches. However, adequate neurally-mechanistic accounts of how meaning might be extracted from language are sorely lacking. Here, we report a first step toward addressing this gap by connecting recent artificial neural networks from machine learning to human recordings during language processing. We find that the most powerful models predict neural and behavioral responses across different datasets up to noise levels. Models that perform better at predicting the next word in a sequence also better predict brain measurements—providing computationally explicit evidence that predictive processing fundamentally shapes the language comprehension mechanisms in the brain. The neuroscience of perception has recently been revolutionized with an integrative modeling approach in which computation, brain function, and behavior are linked across many datasets and many computational models. By revealing trends across models, this approach yields novel insights into cognitive and neural mechanisms in the target domain. We here present a systematic study taking this approach to higher-level cognition: human language processing, our species' signature cognitive skill. We find that the most powerful "transformer" models predict nearly 100\% of explainable variance in neural responses to sentences and generalize across different datasets and imaging modalities (functional MRI and electrocorticography). Models' neural fits ("brain score") and fits to behavioral responses are both strongly correlated with model accuracy on the next-word prediction task (but not other language tasks). Model architecture appears to substantially contribute to neural fit. These results provide computationally explicit evidence that predictive processing fundamentally shapes the language comprehension mechanisms in the human brain.}}

@ARTICLE{Caucheteux2023,
  title    = "Evidence of a predictive coding hierarchy in the human brain
              listening to speech",
  author   = "Caucheteux, Charlotte and Gramfort, Alexandre and King,
              Jean-R{\'e}mi",
  abstract = "Considerable progress has recently been made in natural language
              processing: deep learning algorithms are increasingly able to
              generate, summarize, translate and classify texts. Yet, these
              language models still fail to match the language abilities of
              humans. Predictive coding theory offers a tentative explanation
              to this discrepancy: while language models are optimized to
              predict nearby words, the human brain would continuously predict
              a hierarchy of representations that spans multiple timescales. To
              test this hypothesis, we analysed the functional magnetic
              resonance imaging brain signals of 304 participants listening to
              short stories. First, we confirmed that the activations of modern
              language models linearly map onto the brain responses to speech.
              Second, we showed that enhancing these algorithms with
              predictions that span multiple timescales improves this brain
              mapping. Finally, we showed that these predictions are organized
              hierarchically: frontoparietal cortices predict higher-level,
              longer-range and more contextual representations than temporal
              cortices. Overall, these results strengthen the role of
              hierarchical predictive coding in language processing and
              illustrate how the synergy between neuroscience and artificial
              intelligence can unravel the computational bases of human
              cognition.",
  journal  = "Nat Hum Behav",
  volume   =  7,
  number   =  3,
  pages    = "430--441",
  month    =  mar,
  year     =  2023,
  address  = "England",
  language = "en"
}

@article{desikan2006automated,
  author = {Desikan, Rahul S. and Ségonne, Florent and Fischl, Bruce and Quinn, Brian T. and Dickerson, Bradford C. and Blacker, Deborah and Buckner, Randy L. and Dale, Anders M. and Maguire, R. Paul and Hyman, Bradley T. and Albert, Marilyn S. and Killiany, Ronald J.},
  title = {An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest},
  journal = {NeuroImage},
  volume = {31},
  number = {3},
  pages = {968--980},
  year = {2006},
  doi = {10.1016/j.neuroimage.2006.01.021}
}

@book{cohen1988statistical,
  author = {Cohen, Jacob},
  title = {Statistical Power Analysis for the Behavioral Sciences},
  edition = {2nd},
  publisher = {Lawrence Erlbaum Associates},
  year = {1988},
  address = {Hillsdale, NJ}
}

@article{Grill-Spector2004,
  author = {Grill-Spector, Kalanit and Malach, Rafael},
  title = {The human visual cortex},
  journal = {Annual Review of Neuroscience},
  volume = {27},
  pages = {649--677},
  year = {2004},
  doi = {10.1146/annurev.neuro.27.070203.144220}
}

@article{Kravitz2013,
  author = {Kravitz, Dwight J. and Saleem, Kadharbatcha S. and Baker, Chris I. and Ungerleider, Leslie G. and Mishkin, Mortimer},
  title = {The ventral visual pathway: an expanded neural framework for the processing of object quality},
  journal = {Trends in Cognitive Sciences},
  volume = {17},
  number = {1},
  pages = {26--49},
  year = {2013},
  doi = {10.1016/j.tics.2012.10.011}
}

@article{Fedorenko2024,
  author = {Fedorenko, Evelina and Ivanova, Anna A. and Regev, Tamar I.},
  title = {The language network as a natural kind within the broader landscape of the human brain},
  journal = {Nature Reviews Neuroscience},
  volume = {25},
  number = {5},
  pages = {289--312},
  year = {2024},
  doi = {10.1038/s41583-024-00802-4}
}

@article{Haber2010,
  author = {Haber, Suzanne N. and Knutson, Brian},
  title = {The reward circuit: linking primate anatomy and human imaging},
  journal = {Neuropsychopharmacology},
  volume = {35},
  number = {1},
  pages = {4--26},
  year = {2010},
  doi = {10.1038/npp.2009.129}
}

@article{Diekhof2012,
  author = {Diekhof, Esther K. and Kaps, Lena and Falkai, Peter and Gruber, Oliver},
  title = {The role of the human ventral striatum and the medial orbitofrontal cortex in the representation of reward magnitude - An activation likelihood estimation meta-analysis of neuroimaging studies of passive reward expectancy and outcome processing},
  journal = {Neuropsychologia},
  volume = {50},
  number = {7},
  pages = {1252--1266},
  year = {2012},
  doi = {10.1016/j.neuropsychologia.2012.02.007}
}

@article{Kahnt2010,
  author = {Kahnt, Thorsten and Heinzle, Jakob and Park, Soyoung Q. and Haynes, John-Dylan},
  title = {Decoding different roles for vmPFC and dlPFC in multi-attribute decision making},
  journal = {NeuroImage},
  volume = {52},
  number = {2},
  pages = {506--514},
  year = {2010},
  doi = {10.1016/j.neuroimage.2010.04.229}
}

@article{Seeley2007,
  author = {Seeley, William W. and Menon, Vinod and Schatzberg, Alan F. and Keller, Jennifer and Glover, Gary H. and Kenna, Heather and Reiss, Allan L. and Greicius, Michael D.},
  title = {Dissociable intrinsic connectivity networks for salience processing and executive control},
  journal = {Journal of Neuroscience},
  volume = {27},
  number = {9},
  pages = {2349--2356},
  year = {2007},
  doi = {10.1523/JNEUROSCI.5587-06.2007}
}

@article{MORAWETZ2017111,
title = {The effect of strategies, goals and stimulus material on the neural mechanisms of emotion regulation: A meta-analysis of fMRI studies},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {72},
pages = {111-128},
year = {2017},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2016.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S014976341630375X},
author = {Carmen Morawetz and Stefan Bode and Birgit Derntl and Hauke R. Heekeren},
keywords = {Reappraisal, Suppression, Distraction, Concentration, Reinterpretation, Distancing, Cognitive functions, Emotion regulation processes, Neural networks, Neuroimaging},
abstract = {Emotion regulation comprises all extrinsic and intrinsic control processes whereby people monitor, evaluate and modify the occurrence, intensity and duration of emotional reactions. Here we sought to quantitatively summarize the existing neuroimaging literature to investigate a) whether different emotion regulation strategies are based on different or the same neural networks; b) which brain regions in particular support the up- and down-regulation of emotions, respectively; and c) to which degree the neural networks realising emotion regulation depend on the stimulus material used to elicit emotions. The left ventrolateral prefrontal cortex (VLPFC), the anterior insula and the supplementary motor area were consistently activated independent of the regulation strategy. VLPFC and posterior cingulate cortex were the main regions consistently found to be recruited during the up-regulation as well as the down-regulation of emotion. The down-regulation compared to the up-regulation of emotions was associated with more right-lateralized activity while up-regulating emotions more strongly modulated activity in the ventral striatum. Finally, the process of emotion regulation appeared to be unaffected by stimulus material.}
}

@article{Morawetz2021,
    author = {Morawetz, Carmen and others},
    title = {Emotion regulation modulates dietary decision-making via activity in the prefrontal-striatal valuation system},
    journal = {Cerebral Cortex},
    year = {2021},
    doi = {10.1093/cercor/bhaa398}
  }


@article{Corbetta2002,
  author = {Corbetta, Maurizio and Shulman, Gordon L.},
  title = {Control of goal-directed and stimulus-driven attention in the brain},
  journal = {Nature Reviews Neuroscience},
  volume = {3},
  number = {3},
  pages = {201--215},
  year = {2002},
  doi = {10.1038/nrn755}
}

@article{Hickok2007,
  author = {Hickok, Gregory and Poeppel, David},
  title = {The cortical organization of speech processing},
  journal = {Nature Reviews Neuroscience},
  volume = {8},
  number = {5},
  pages = {393--402},
  year = {2007},
  doi = {10.1038/nrn2113}
}

@article{Eichenbaum2017,
  author = {Eichenbaum, Howard},
  title = {Prefrontal-hippocampal interactions in episodic memory},
  journal = {Nature Reviews Neuroscience},
  volume = {18},
  number = {9},
  pages = {547--558},
  year = {2017},
  doi = {10.1038/nrn.2017.74}
}

@article{Grabenhorst2013,
  author = {Grabenhorst, Fabian and Schulte, Frank P. and Maderwald, Stefan and Brand, Matthias},
  title = {Food labels promote healthy choices by a decision bias in the amygdala},
  journal = {NeuroImage},
  volume = {74},
  pages = {152--163},
  year = {2013},
  doi = {10.1016/j.neuroimage.2013.02.012}
}

@article{StYves2023,
  author = {St-Yves, Ghislain and Allen, Emily J. and Wu, Yihan and Kay, Kendrick and Naselaris, Thomas},
  title = {Brain-optimized deep neural network models of human visual areas learn non-hierarchical representations},
  journal = {Nature Communications},
  volume = {14},
  pages = {3329},
  year = {2023},
  doi = {10.1038/s41467-023-38674-4}
}
