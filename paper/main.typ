
#import "@preview/starter-journal-article:0.5.1": article, author-meta
#import "@preview/subpar:0.2.2"
#import "./header.typ": set_abstract, set_affiliation, set_author_info, set_body, set_title
#import "./settings.typ": settings
#import "./header.typ": appendix, make_cover

#set page(paper: "a4", margin: 5em, numbering: "1")

#show figure.caption: it => {
  set text(0.8em)
  set align(left)
  it
}
#show figure.where(kind: "subfigure"): it => {
  show figure.caption: set text(0.8em)
  it
}

#make_cover(
  thesis_type: "令和７年度 修士論文",
  title: "食べ物の好みの脳計算過程：深層学習による表現",
  etitle: "Neural computations underlying food preferences: modeling with deep learning",
  author: "青木悠飛",
  eauthor: "Yuhi Aoki",
  affiliation: "一橋大学大学院ソーシャル・データサイエンス研究科",
  eaffiliation: "Graduate School of Social Data Science, Hitotsubashi University",
  date: "2025年1月 提出",
  edate: "January 2025",
  show_english: false,
  show_logo: true,
  logo_path: "image/logo.pdf", // TypstがPDF形式を読み込めない場合はPNG/SVGに変換
  logo2_path: "image/sds.pdf",
)


#set_abstract(settings.abstract, settings.keywords)

#let figure_supplement = "図"

#show outline: out => {
  show heading: set text(size: 1.2em, font: "BIZ UDPGothic")
  show heading.where(level: 1): it => block(below: 2em)[
    #it
  ]
  set text(font: "BIZ UDPGothic")
  out
}

#show outline.entry.where(
  level: 1,
): it => [
  #set block(above: 1.5em, below: 1em)
  #text(
    it.indented(it.prefix(), it.body() + h(1fr) + text(it.page(), weight: "regular", size: 10pt)),
    size: 1.1em,
    weight: "semibold",
  )
]

#show outline.entry.where(
  level: 2,
): it => [
  #set block(above: 1.2em)
  #text(it, size: 10pt)
]

#show outline.entry.where(
  level: 3,
): it => [
  #set block(above: 1.1em)
  #text(
    it.indented(
      it.prefix(),
      it.body() + box(width: 1fr, it.fill) + text(it.page(), weight: "regular", size: 10pt),
    ),
    size: 0.8em,
  )
]

#pagebreak()

#outline(
  title: "目次",
  depth: 3,
  indent: auto,
)


#pagebreak()

#show outline.entry.where(
  level: 1,
): it => [
  #set block(above: 1.5em, below: 1em)
  #set text(font: "BIZ UDPMincho", size: 0.9em)
  #it.indented(it.prefix(), it.body() + h(1fr) + text(it.page(), weight: "regular", size: 0.9em, font: "BIZ UDPGothic"))
]


#outline(
  title: "図表目次",
  depth: 2,
  indent: auto,
  target: figure,
)


#set_body(
  block()[
    = はじめに

    摂食行動は人間の生存に不可欠であり、「何を食べるか」の選択は日常生活における中心的な関心事である。こうした決定は、利用可能な選択肢の主観的価値を比較することで下されると考えられている@Rangel2008。偏った食物選好は肥満や摂食障害と関連しており@Foerde2015 @Spinelli2021-yi、2021年には、食生活リスクに起因する死亡は約800万人に上る@VADUGANATHAN20222361。これらの知見から、食の意思決定の偏りによって健康被害が生じ、死亡に繋がっている可能性がある。そのため、主観的価値の計算方法を解明することが不適切な食事選択の解決策となり、公衆衛生の向上に寄与する可能性がある。

    食品の主観的価値は、栄養成分、味、健康への影響、見た目、価格などさまざまな要因によって影響を受ける @Hare2009 @Suzuki2017-wk @Motoki2020-lf @54030559-6348-39cf-abea-9a63f249f992。最終的な統合された主観的価値は腹内側前頭前野（vmPFC）で表出されると考えられている @Chib2009-jq。さらに、脳内における主観的価値の計算は抽象化の度合いに応じて階層的かつ分散的に情報を処理するという仮説がある。しかし、感覚表象から主観的価値を計算する脳の中間過程は、それが階層的であるか否かを含め、依然としてほとんど解明されていない。

    計算神経科学は、脳のメカニズムに関する仮説を数学的モデルやアルゴリズムとして定式化し、脳を情報処理システムとして理解しようとするアプローチである。これらのモデルは、行動データやfMRIなどの脳活動データと比較を行うことで、複雑な脳の計算過程を解明することにつながる。認知科学における従来のトップダウンアプローチでは、理論をモデル化し実験で検証することで単一ニューロンや小規模な固定回路の解明してきたが、可塑性を持つ神経回路の詳細な計算過程をモデル化するには、複雑なモデルが必要である@Kriegeskorte2018 @Richards2019。このため近年、人工ニューラルネットワーク（ANN）を用いたボトムアップアプローチが注目を集めている。ANNは脳の構造と機能に着想を得ており、層状に情報を処理する相互接続されたノード（ニューロン）で構成される。大規模データセットでANNを学習させることで、人間レベルの認知タスクを遂行できるようになり、脳の計算過程をモデル化する有望な手段となっている。

    最近の研究では、深層畳み込みニューラルネットワーク（DCNN）や大規模言語モデル（LLM）の内部表現を人間の行動や脳活動と比較することで、知覚・認知・評価のメカニズムの解明が始まっている @Yamins2014-it @Kriegeskorte2015 @Iigaya2021 @Iigaya2023 @Lahner2024 @Doerig2025。DCNNは視覚処理の階層構造を模倣し、画像認識において人間レベルの性能を達成するため、神経処理の有望な計算モデルとして機能する。例えば、飯ヶ谷らは美術作品の主観的価値を予測するDCNNを構築し、低次画像特徴が初期層で捕捉される一方、高次抽象特徴が後続層で出現することを示した@Iigaya2021。一方、LLMは人間の脳とは異なる複雑な構造を持つと考えられ、LLMと脳の内部構造を厳密に比較する方法はほとんどない。それでも、DoerigらはLLMの最終埋め込みを脳と比較し、LLMが高次視覚野に類似していることを示した@Doerig2025。これらの研究は、深層ニューラルネットワーク（DNN：DCNNやLLMを含む）と脳が計算プロセスにおいて比較可能かつ部分的に類似していることを示している。

    本研究では、DNNのモデリングと解析を通じて、食品画像から主観的価値（好み）の計算プロセスを解明することを目的とする。まず、食品画像から主観的価値を予測するDNNを訓練し、層ごとの活性化パターンを分析することで、どの段階（層）でどの種類の情報（低次画像特徴、栄養成分、美味しさ、健康性）が表現されているかを検証する。次に、fMRIデータとDNNの最終または中間表現を比較し、脳とDNNが類似する領域を分析する。このアプローチにより、脳が視覚情報を処理・統合して最終的な主観的価値の計算過程に関する知見が得られる。

    = 関連研究
    == 主観的価値
    主観的価値とは、意思決定の際に用いられる「共通通貨」である。主観的価値は、経済学の期待効用理論の効用から生まれた、神経科学、心理学、経済学の共通の概念的枠組みである @Glimcher2004。 Levyらは、主観的価値が異なる報酬カテゴリーにわたって内側前頭前皮質（MPFC）で表現されることを示した @Levy118。さらに、Grossらは、前頭前野の価値信号が異なる報酬カテゴリー（活動とスナック菓子）にわたって個人の嗜好を予測できることを示した @Gross7580。このため、主観的価値という共通価値を表現する脳領域は共通であると考えられている。

    具体的な神経プロセスとして、主観的価値は脳内の前頭前野、線条体などの複数の領域にわたって表現され、最終的にvmPFCで主観的価値が表現される。Hareらは、食品画像とfMRIを使って、主観的価値の予測は内側眼窩前頭皮質、実際の主観的価値は中心眼窩前頭皮質の活動と相関し、主観的価値の予測誤差は腹側線条体の活動と相関していることを示した @Hare5623。Samejimaらは、サルの線条体における行動特異的な報酬価値の表現が行動選択を導くことを示唆した @Samejima2005。主観的価値の最終的な計算表現は明らかになっている一方で、感覚情報から主観的価値を計算する中間過程は依然として不明な部分が多い。

    食品の主観的価値は、味や見た目以外のさまざまな要因も考慮して計算されることがわかっている。Suzukiらは、食品の主観的価値が栄養属性（タンパク質、脂質、炭水化物、ビタミン）に基づいて計算されることを示した@Suzuki2017-wk。Motokiらは、食品の主観的価値がラベル、ブランド、価格などの外的要因によっても影響を受けることを示した@Motoki2020-lf。これらの研究は、食品の主観的価値が多次元的な情報から計算されることを示している。しかし、視覚情報からこれらの属性を抽出し、最終的な主観的価値を計算する中間過程は依然として不明である。

    主観的価値の計算を理解するために、学習理論やプロスペクト理論などの理論を計算モデルに落とし込み、計算過程を比較する試みがなされている。例えば、強化学習モデルを用いて線条体、腹内側前頭前皮質（vmPFC）の活動をモデリングし、線条体やvmPFCが強化学習モデルと近い動きをしていることを明らかにした @Hampton8360 @Rutledge2014。Suzukiらは、意思決定の線形モデルを構築し、fMRIデータを比較し、意思決定の要因が、自身の選好と過去の選択に関する情報、他者の選択肢の評価であり、それらが異なる脳領域で計算していることを示した @Suzuki2015-ey。Yaminsらは、DCNNを用いて視覚野の神経応答を予測し、DCNNの高次層が下側頭葉皮質の神経応答を予測することを示した @Yamins2014-it。これらの知見は、計算モデルを用いて主観的価値の計算過程を理解する有望なアプローチであることを示している。

    == 深層ニューラルネットワーク（DNN）
    DNNは、脳の構造と機能に着想を得ており、層状に情報を処理する相互接続されたノード（ニューロン）で構成される。その中でも、DCNNは視覚処理の階層構造を模倣し、画像認識において人間レベルの性能を達成するため、視覚情報処理の有望な計算モデルとして機能する @Yamins2014-it @Kriegeskorte2015。DCNNは、畳み込み層、プーリング層、全結合層などの複数の層で構成され、各層は前の層からの入力を受け取り、特徴マップを生成する。初期層はエッジやテクスチャなどの低次特徴を抽出し、後続層はオブジェクトの形状やカテゴリなどの高次特徴を抽出する。DCNNは、ImageNetなどの大規模データセットで学習され、人間レベルの画像認識性能を達成している @Deng2009 @Krizhevsky2012。そのため、DCNNは視覚情報処理の計算モデルとして利用可能であり、脳の視覚野の神経応答と比較することで、視覚情報処理のメカニズムの解明に寄与する可能性がある。

    LLMは、自然言語処理タスクにおいて人間レベルの性能を示す。多くのLLMは、トランスフォーマーアーキテクチャに基づいており、自己注意メカニズムを用いて入力シーケンス内の異なる位置の情報を動的に重み付けする。LLMは、大規模なテキストデータセットで学習され、文の生成、質問応答、翻訳などのタスクで優れた性能を示している @Vaswani2017 @Brown2020 @openai2023。LLMは、文脈情報を考慮した単語の意味表現を学習し、文の意味理解に寄与している。そのため、 LLMを脳の言語処理に関与する領域と比較することで、言語処理のメカニズムの解明に寄与する可能性がある @Schrimpf2021 @Caucheteux2023。


    == DNNと脳の比較
    DNNと脳を比較することで、モデルのどの部分が脳領域に類似しているのか調べる試みがある。Yaminsらは、DCNNの高次層が下側頭葉皮質の神経応答を予測することを示した @Yamins2014-it。DCNNの層ごとの特徴表現は、脳の視覚野の階層的な情報処理と類似していることが示されている。Iigayaらは、DCNNを用いて美術作品の主観的価値を予測し、低次画像特徴が初期層で捕捉される一方、高次抽象特徴が後期層で出現することを示した @Iigaya2021。Doerigらは、LLMの最終埋め込みを脳と比較し、LLMが高次視覚野に類似していることを示した @Doerig2025。これらの研究は、脳とモデルの構造を比較することで、脳のどの領域でどの情報が使われているか明らかにすることができることを示唆している。そのため、主観的価値の計算においても、LLMを含めたDNNと脳が比較することで、主観的価値の計算過程に関する新たな知見を提供する可能性がある。

    = 目的
    本研究では、DNNのモデリングと解析を通じて、食品の主観的価値（好み）の計算プロセスを解明することを目的とする。具体的には、以下の研究目的で検証を行う。

    - *研究目的1：DNNは食品画像から主観的価値を予測できるか*

    食品画像の視覚特徴から主観的価値を予測するDNNモデルを構築し、その予測精度を評価する。特に、視覚情報のみを扱うDCNN（ConvNeXt、ResNet、VGG）と、視覚-言語情報を統合するCLIPを比較することで、言語的・意味的情報の寄与を検討する。

    - *研究目的2：DNNの各層でどのような情報が表現されているか*

    DNNの層ごとの活性化パターンを分析し、異なる種類の情報（低次画像特徴、栄養属性、美味しさ、健康性、主観的価値）がどの層で表現されているかを検証する。先行研究@Iigaya2021 に基づき、低次特徴は初期層、高次属性は後期層で表現されるという階層的処理仮説を検証する。

    - *研究目的3：DNNは脳の表現構造をどの程度説明できるか*

    表現類似性解析（RSA）を用いてDNNと脳の表現類似度を定量化し、ノイズ上限値を基準としてモデルの説明力を評価する。ノイズ上限値は被験者間の一致度から推定される理論的上限であり、これに対するモデルの到達度を検証することで、DNNが脳の表現をどの程度捉えているかを明らかにする。

    - *研究目的4：DNNの層構造は脳の情報処理階層と対応するか*

    fMRIデータとDNNの層別活性化パターンを比較し、以下の仮説を検証する：
    - *仮説4a*：視覚モデル（DCNN）の初期層は一次視覚野、後期層は高次視覚野および価値関連領域（vmPFC）と対応する
    - *仮説4b*：視覚-言語モデル（CLIP）は、意味・言語・価値関連領域と対応する

    *期待される貢献*

    本研究は、（1）DNNモデルを使って、画像から食品の主観的価値はどれだけ予測可能か、（2）視覚-言語統合が食品の価値評価に与える影響を神経科学的に検証すること、（3）ノイズ上限値を用いてDNNの脳表現をどれぐらい説明できるかを定量化すること、（4）新たな手法である階層的PCAを用いたGLMで、DNNと脳を比較することで、食品の主観的価値の詳細な中間処理過程を明らかにすることを目的とする。

    = 方法
    本研究では、オンライン調査で収集した食品画像に対する主観的価値評価データを使用し、DNNの学習と解析を行った。さらに、fMRIデータを用いて、DNNの最終および中間表現と脳活動パターンの比較を行った。

    == オンライン調査
    オンライン調査には、20歳から72歳までの健康な成人男女200名（平均年齢39.08歳）が参加した。参加者は、Food-Pics @foodpics2014 @foodpics2019 から896枚の食品画像に対して、「好み」（主観的価値）、「美味しさ」、「健康性」を8段階リッカート尺度（1 = 強く不同意、8 = 強く同意）で評価した。データ不備により1名、回答パターンに基づく品質管理（75%以上の試行で同一回答、または選択肢の使用が4種類以下かつ65%以上で同一回答）により10名、計11名を除外した後、残りの189名の評価を各画像ごとに平均化した（@fig:rank は主観的価値による上位および下位の画像の例を示す）。なお、主観的価値は美味しさと強い正の相関（r = 0.849, p < 0.001）、健康性とも中程度の正の相関（r = 0.496, p < 0.001）を示し、美味しさと健康性の間にも中程度の正の相関（r = 0.485, p < 0.001）が認められた。これらの相関パターンは、主観的価値が美味しさと健康性の両方によって駆動されていることを示唆している。研究は国立精神・神経医療研究センター倫理委員会の承認を受けて実施された。


    #figure(
      image("./image/top_bottom_subjective_value.png", width: 80%),
      supplement: figure_supplement,
      caption: [主観的価値による上位（上）および下位（下）の食品画像の例。],
    ) <fig:rank>


    == fMRI実験
    === 参加者
    fMRI実験には、オンライン調査とは別に健康な成人男女31名（年齢：平均21.29歳、範囲18–25歳、女性11名）が参加した。全員が右利きであり、神経学的または精神医学的疾患の既往歴はなかった。参加者は研究の目的と手順について説明を受け、書面によるインフォームドコンセントを提供した。研究は一橋大学倫理委員会の承認を受けて実施された。

    === 刺激
    刺激には、Food-Pics @foodpics2014 @foodpics2019 から選択された568枚の食品画像を使用した。これらの画像は、さまざまな食品カテゴリー（果物、野菜、スナックなど）を網羅している。

    === fMRI実験手続き
    fMRI実験では、参加者はスキャナー内で食品画像を視覚的に評価した。各試行では、食品画像が4秒間表示され、その後、2.5秒間の評価期間が続いた。参加者は、4段階リッカート尺度（1 = 強く不同意、4 = 強く同意）を使用して、画像に対する「好み」（主観的価値）を評価した。全体で568試行があり、各参加者は3日間にわたり1日あたり4回のセッションに分けて実施した。試行間には2〜12秒（平均7秒）のランダムなインターバルが設けられた。刺激提示とデータ収集はPsychoPyを用いて行われた（@fig:fmri_task, fMRIの基本的な知識については@app1[付録] を参照）。

    #figure(
      // Replace the rectangle with an image once available:
      image("./image/experiments_design.png", width: 80%),
      supplement: figure_supplement,
      caption: [食品評価課題における1試行のタイムライン。各試行において、参加者は1つの食品に対する「どのぐらい欲しいか」（すなわち主観的価値）を報告した。この評価は支払意思額（Willingness to Pay; WTP）に類似した概念であり、食品に対する動機づけの強さを反映している。評価フェーズでは、キーと選択肢の順序が試行間でランダム化されている。],
    ) <fig:fmri_task>


    === 使用したDNNモデル
    本研究では、3つの異なるDCNNアーキテクチャ（VGG、ResNet、ConvNeXt）を使用して、食品画像から主観的価値を予測するモデルを構築した。さらに、マルチモーダルモデルであるCLIPも使用し、画像エンコーダーの最終埋め込みを用いて主観的価値を予測した。（DNNについては @app2[付録] @app3[付録] を参照）

    ==== VGG
    VGGは、Visual Geometry Groupによって開発された深層畳み込みニューラルネットワーク（CNN）アーキテクチャであり、画像認識タスクで高い性能を示している @simonyan2015。VGGは、非常に深い層構造を持ち、3x3の小さな畳み込みフィルターを使用して特徴抽出を行う。VGGは、16層（VGG16）および19層（VGG19）のバリエーションがあり、各層は畳み込み層、プーリング層、および全結合層で構成されている。

    ==== ResNet
    ResNet（Residual Network）は、Microsoft Researchによって開発された深層畳み込みニューラルネットワーク（CNN）アーキテクチャであり、非常に深いネットワークの学習を可能にするための残差学習フレームワークを導入している @he2015。ResNetは、スキップ接続（skip connections）を使用して、層間の情報伝播を容易にし、勾配消失問題を軽減する。各ResNetブロックは、複数の畳み込み層とバッチ正規化層、およびReLU活性化関数で構成されている。

    ==== ConvNeXt
    ConvNeXtは、従来の畳み込みニューラルネットワーク（CNN）アーキテクチャを改良したものであり、Vision Transformer（ViT）の設計原則を取り入れている @liu2022convnet2020s。ConvNeXtは、深い層と広い受容野を持つことで、高次特徴の抽出能力が向上している。また、ConvNeXtは、正規化手法や活性化関数の選択など、最新の技術を採用しており、従来のCNNと比較して性能が向上している。

    ==== CLIP
    CLIP（Contrastive Language-Image Pretraining）は、OpenAIによって開発されたマルチモーダルモデルであり、画像とテキストのペアを用いて学習されている @Radford2021。CLIPは、画像エンコーダーとテキストエンコーダーの2つの主要なコンポーネントで構成されており、これらは共通の埋め込み空間にマッピングされる。CLIPは、大規模なインターネットデータセットから収集された画像とテキストのペアを使用して学習されており、ゼロショット学習能力を持つ。つまり、CLIPは事前に見たことのないクラスの画像に対しても、高い分類性能を示すことができる。CLIPは、画像キャプション生成、画像検索、視覚質問応答などのさまざまなタスクで優れた性能を示している。CLIPは視覚情報処理と自然言語処理の計算モデルとして、脳の視覚野および言語処理に関与する領域の神経応答と比較することで、これらの情報処理メカニズムの解明に寄与する可能性がある。

    == DNNモデルの訓練
    === 交差検証とデータ拡張
    データリークを防ぐため、まず896枚の元画像を6分割し、各フォールドで5分割を訓練用、1分割を検証用とした。データ拡張は訓練フォールドのみに適用し、検証フォールドには元画像のみを使用した。これにより、同一元画像由来の拡張版が訓練・検証間で重複することを防いだ。

    訓練フォールドに適用したデータ拡張手法は以下の通りである：リサイズ（240×240）、センタークロップ（224×224）、水平反転、アフィン変換（±20%、上下左右への平行移動20%、スケール70–120%）、ガウシアンブラー（カーネル5×5、σ = 0.01–4.0）、カラージッター（明るさ7.5%、色相3%、彩度3%）、正規化（訓練セットの平均と標準偏差に基づく）。各元画像に対して5つの拡張バージョンを生成し、訓練セットを6倍に拡大した。

    === モデル訓練
    事前学習済みのConvNeXt-Base、ResNet152、およびVGG16モデルを使用し、最終の全結合層を主観的価値スコア（1–8）を出力するように置き換え、全層をファインチューニングした。損失関数にはHuber損失（δ = 1）を使用し、AdamWオプティマイザを用いて学習を行った。学習率は1e-4、ミニバッチサイズは373（GPUメモリ制約による）、エポック数は250とした。6分割交差検証における各検証フォールドからの予測を連結し、実際の評価との相関を計算した。計算環境は、Intel Xeon w5-2465XプロセッサとRTX 4000 Ada GPUを搭載し、Python 3.12.7およびPyTorch 2.5.0（CUDA対応）を使用した。

    == DNNモデル評価
    === 事前学習モデルの評価
    事前学習済みモデル（ファインチューニングなし）の予測性能を評価するため、各モデルの最終層手前から特徴量を抽出した：VGG16はavgpool後（25,088次元）、ConvNeXt-Baseはavgpool後（1,024次元）、ResNet152はavgpool後（2,048次元）、CLIPはencode_image出力（768次元）。抽出した特徴量はPCAにより512次元に統一し、リッジ回帰（α = 1.0）を用いて主観的価値を予測した。8分割交差検証により性能を評価し、予測と実際の評価とのピアソン相関係数を算出した。

    === ファインチューニングモデルの評価
    DCNNモデル（ConvNeXt、ResNet、VGG）の性能は、6分割交差検証における予測評価と実際の評価との相関係数（Pearsonの相関係数）で評価した。各モデルの予測精度を比較し、最も高い相関を示したモデルを特定した。

    == DNNのデコーディング解析
    DNNの各層の活性化パターンを分析し、異なる種類の情報（低次画像特徴、栄養属性、美味しさ、健康性、主観的価値）がどの層で表現されているかを調査した。各層について、896 × d（画像 × ユニット）の活性化マトリックスを構築し、主成分分析（PCA）を適用して累積説明分散が80%に達するまで次元削減を行い、得られた主成分をリッジ回帰の予測子として使用して各属性（主観的価値、美味しさ、健康性、色、栄養）を推定した。正則化パラメータは8分割交差検証で最適化し、性能は予測と実際の評価との相関係数（Pearsonの相関係数）で評価した（ @app4[付録] を参照）。


    == fMRIデータ収集
    fMRI画像は、一橋大学に設置された3テスラのMRIスキャナー（Siemens MAGNETOM Prisma）を使用して収集された。機能的画像は、T2$*$強調マルチバンドエコープラナーイメージング（MB-EPI）シーケンスで取得された。主な取得パラメータは以下の通りである：繰り返し時間（TR）800 ms、エコー時間（TE）34.4 ms、フリップ角52度、マルチバンドファクター6、ボクセルサイズ2.4 × 2.4 × 2.4 mm、マトリックスサイズ86 × 86。各セッションで700ボリュームが取得された（スキャン時間：約560秒）。受信には32チャンネルヘッドコイルを使用した。高解像度のT1強調構造画像も取得された（MPRAGEシーケンス）。fMRIデータは、MATLAB R2025aおよびMacBook Pro (14インチ, M4 Pro, 2024, Mac OS X 15.1）上でSPM25を用いて解析した。データ収集および解析は、実験条件を盲検化せずに実施した。

    == fMRIデータ前処理
    fMRIデータの前処理は、fMRIPrep 23.2.1 @Esteban2018-xz を使用して行われた。前処理手順には、以下が含まれる：スライスタイミング補正、モーション補正、コレジストレーション、空間正規化（MNI152NLin2009cAsymテンプレートへの変換）。この処理の後に、空間平滑化（6 mm FWHMガウスカーネル）がSPM25で実施された。前処理後のデータは、統計解析およびDCNNとの比較のために使用された。

    == fMRIデータ解析

    === GLM分析
    一般線形モデル（GLM）に基づいて行われた（@app5[付録] を参照）。各参加者の前処理済みfMRIデータに対して、以下の条件を含むGLMを構築した：

    1. *Image条件*：食物画像提示期間（画像提示から質問提示まで）。この条件には、以下の8つのパラメトリックモジュレーター（parametric modulator）を含めた：
      - 主観的価値（Value）：参加者が評定した食物の好ましさ
      - 色情報（R, G, B）：画像の赤・緑・青チャンネルの平均値
      - 栄養成分（Protein, Fat, Carbs, Kcal）：食品のタンパク質、脂質、炭水化物、カロリー
    2. *Question条件*：質問提示期間（質問提示から評定開始まで）
    3. *Response条件*：評定応答時点（持続時間0秒）
    4. *Feedback条件*：フィードバック提示期間（0.5秒）
    5. *Miss条件*：応答がなかった試行全体

    パラメトリックモジュレーターは直交化せずにモデルに投入し（orth = 0）、各変数の独立した効果を推定した。さらに、6つの頭部運動パラメータを共変量として含めることで、頭部運動の影響を統計的に除去した。各条件は、試行開始時点でのオンセットと持続時間に基づいてモデル化され、各参加者のデザインマトリックスが構築された。GLMはSPM25で実装され、各参加者のベータ画像が推定された。

    === 集団レベル解析
    各参加者の個別レベルのGLM解析結果を用いて、グループレベルのランダム効果解析（one-sample t-test）を実施した（@app6[付録] を参照）。主観的価値に関連する脳領域を特定するために、クラスターレベルFWE補正を適用した（クラスター形成閾値：p < 0.001 uncorrected、クラスターレベルFWE：p < 0.05；@app7[付録] を参照）。クラスターレベルFWE補正はSPMのランダム場理論（Random Field Theory; RFT）に基づき、多重比較補正を行った。

    === 表現類似性解析（RSA）
    DNNの内部表現と脳活動パターンの構造的類似性を評価するため、表現類似性解析（RSA）@Kriegeskorte2008 を実施した（@app8[付録] を参照）。RSAでは、刺激セット内の各ペア間の神経活動パターンの非類似度を表現非類似度行列（RDM）として表現し、異なるシステム（脳とDNN）間のRDMを比較することで、表現構造の類似性を定量化する。

    ==== ROI-RSA
    ROI-RSAでは、Harvard-Oxford確率的アトラス@Makris2006 @Frazier2005 から31個のROIを定義した（25%以上の確率を示すボクセルを含む）。視覚皮質（V1、初期視覚野、LOC、紡錘状回、IT）、頭頂葉（SPL、IPL、角回、楔前部）、側頭葉（STG、MTG、側頭極、PHC）、前頭葉（IFG、Broca野、DLPFC、VLPFC、OFC、前頭極）、帯状皮質（ACC、PCC）、島皮質、および皮質下構造（海馬、扁桃体、尾状核、被殻、側坐核、視床、淡蒼球）を含めた。

    各ROIにおいて、Least Squares Separate（LSS）法@Mumford2012 を用いて各食品画像に対する単一試行ベータ値を推定した。490枚の共通画像について、各被験者のROI内のベータパターンから表現類似度行列（RDM）を構築した（1 - Pearsonの相関係数）。DNNの各層についても、同じ490枚の画像に対する活性化パターンからRDMを算出した。脳RDMとDNN RDMの類似度はスピアマン相関で評価した。

    モデルの説明力の上限を評価するため、Leave-One-Out法によるノイズ上限値（NC）を算出した。NC上限は各被験者のRDMと全被験者平均RDMとの相関の平均値として、NC下限は各被験者のRDMと当該被験者を除いた残りの被験者の平均RDMとの相関の平均値として定義した。NC上限比（モデル相関 / NC上限 × 100）により、理論的に達成可能な最大説明力に対するモデルの到達度を評価した。

    === エンコーディング解析
    DNNの各層の活性化パターンとfMRIデータの脳活動パターンを比較するために、3レベル階層的PCA（主成分分析）を用いた（@app9[付録] を参照）。この手法は、DNNの活性化パターンを直交化された階層構造に分解し、fMRIデータの予測子として使用する。

    まず、DNNの層を階層的な情報処理段階に基づいて4つのグループに分類した：(1) *Initial層*：低次視覚特徴（エッジ、テクスチャ）を抽出する初期層、(2) *Middle層*：中次特徴を抽出する中間層、(3) *Late層*：高次特徴（オブジェクトの形状やカテゴリ）を抽出する後期層、(4) *Final層*：最終的な分類や埋め込み表現を生成する層。ConvNeXtとCLIPは共にConvNeXt-Baseアーキテクチャを画像エンコーダーとして使用しているため、対応する層グループを同一の基準で抽出した。ConvNeXtでは、Initial層にfeatures_1およびfeatures_3の全ブロックとfeatures_5の初期ブロック（0-3）、Middle層にfeatures_5の中間ブロック（4-13）、Late層にfeatures_5の後期ブロック（14-22）、Final層にfeatures_5の最終ブロック（23-26）とfeatures_7の全ブロックおよびclassifier_1を含めた。CLIPでは、Initial層にstage0-1の全ブロックとstage2の初期ブロック（0-3）、Middle層にstage2の中間ブロック（4-13）、Late層にstage2の後期ブロック（14-22）、Final層にstage2の最終ブロック（23-26）とstage3の全ブロックおよびheadを含めた。

    #figure(
      table(
        columns: (auto, 1fr, 1fr),
        align: (center, left, left),
        [*層グループ*], [*ConvNeXt*], [*CLIP*],
        [Initial], [features_1, features_3, features_5[0-3]], [stage0-1, stage2[0-3]],
        [Middle], [features_5[4-13]], [stage2[4-13]],
        [Late], [features_5[14-22]], [stage2[14-22]],
        [Final], [features_5[23-26], features_7, classifier_1], [stage2[23-26], stage3, head],
        stroke: (x, y) => if y == 0 {
          if x == 0 {
            (right: 0.7pt + black, bottom: 0.7pt + black)
          } else {
            (bottom: 0.7pt + black)
          }
        } else if x == 0 {
          (right: 0.7pt + black)
        },
      ),
      caption: [ConvNeXtおよびCLIPの層グループ分類],
      supplement: "表",
    )


    次に、3レベル階層的PCAを適用した。各画像について各層の活性化を抽出し、以下の3レベルの主成分を算出した：
    + *Global PC*：すべての層に共通する分散を捕捉する主成分（累積寄与率60%に達するまで抽出）
    + *Layer-Shared PC*：隣接する層グループ間で共有される分散を捕捉する主成分（正準相関分析（CCA）を用いて抽出、各隣接ペアについて2成分ずつ、計6成分）
    + *Layer-Specific PC*：各層グループに固有の分散を捕捉する主成分（GlobalおよびShared成分を除去した残差に対して、累積寄与率50%に達するまでPCAを適用）

    累積寄与率の閾値は、情報保持とモデルの簡潔さのバランスを考慮して事前に設定した。Global PCでは全層に共通する主要な分散構造を捕捉するため比較的高い閾値（60%）を、Layer-Specific PCでは共有成分除去後の残差から層固有の情報を抽出するためより低い閾値（50%）を採用した。各レベルの主成分は、QR分解を用いて相互に直交化し、共線性を排除することで各レベルの独立した説明力を評価可能とした。

    GLMでは、これらの主成分を画像提示時のパラメトリックモジュレータとして使用した。パラメトリックモジュレータは日ごとにまとめ（3セッション）、画像提示時の定数項はランごとに設定した。SPMの自動直交化は無効化し（orth = 0）、事前に直交化された主成分構造を保持した。6つの頭部運動パラメータもランごとに共変量として含めた。統計的検定のためのコントラストはセッション間で平均化した。

    統計検定では、各レベルおよび各層グループについてF検定を用いて説明力を評価した：
    + Global_F：すべてのGlobal PCの説明力
    + 各層グループのF検定（Initial_F、Middle_F、Late_F、Final_F）：各層グループ固有のLayer-Specific PCの説明力
    + 各層グループ+関連Shared（例：Initial_withShared_F）：Layer-Specific PCと関連するLayer-Shared PCを組み合わせた説明力
    + 各sharedペアのF検定（例：Initial-Middle_Shared_F）：隣接する層グループ間で共有されるLayer-Shared PCの説明力

    有意な脳領域を同定するため、クラスターレベルFWE補正を適用した（クラスター形成閾値：p < 0.001 uncorrected、クラスターレベルFWE：p < 0.05）。本研究では2モデル（ConvNeXt、CLIP）×10コントラストの計20回の統計検定を実施した。コントラスト間のBonferroni補正は以下の理由から適用しなかった：(1) Global PC、Layer-Shared PC、Layer-Specific PCは3レベル階層的PCAにより直交化されており、各成分は統計的に独立した分散を捉えている、(2) 各層グループ（Initial、Middle、Late、Final）は視覚処理の異なる階層段階に対応し、先行研究に基づく事前仮説を検証している@Yamins2014-it @Kriegeskorte2015、(3) 2つのモデル（ConvNeXt、CLIP）は異なるアーキテクチャと学習目標を持ち、独立した計算仮説を表現している。各コントラスト内ではクラスターレベルFWE補正により偽陽性率を厳密に制御した。さらに、グループレベルのランダム効果解析を行い、各レベルおよび各層グループと有意に相関する脳領域を同定した（クラスターレベルFWE補正、p < 0.05）。

    ==== ROI解析
    仮説駆動型の解析として、先行研究に基づいて定義した16個の関心領域（ROI）における効果を検証した。これらの16 ROIは、ROI-RSAで使用した31 ROIの中から、視覚処理および価値処理に関する先行研究の知見に基づいて選定したサブセットである。ROIはHarvard-Oxford確率的アトラス@Makris2006 @Frazier2005 を用いて定義し、25%以上の確率を示すボクセルを含めた。

    視覚処理に関連するROIとして、一次視覚野（V1）、外側後頭皮質（LOC）、紡錘状回（Fusiform）、下側頭回（IT）を定義した。価値処理に関連するROIとして、腹内側前頭前皮質（vmPFC）、眼窩前頭皮質（OFC）、前帯状皮質（ACC）、側坐核（NAcc）、線条体（Striatum：尾状核+被殻）を定義した。その他のROIとして、島皮質（Insula）、扁桃体（Amygdala）、海馬（Hippocampus）、海馬傍回（PHC）、上頭頂小葉（SPL）、楔前部（Precuneus）、角回（Angular Gyrus）を含めた。

    各ROIにおいて、Small Volume Correction（SVC）を適用し、ROI内でのFWE補正を行った（p < 0.05）。SVCはランダム場理論に基づき、各ROIのボクセル数と平滑度推定値（FWHM）から算出したRESEL（resolution element：空間平滑化後のデータにおける独立な解像度要素）数を用いてp値を補正した。効果量はβ値のRMS（二乗平均平方根）として算出した。

    = 結果

    == DNNモデルによる主観的価値予測
    3つのDCNNモデル（ConvNeXt、ResNet、VGG）とCLIPを用いて、食品画像から主観的価値を予測した（@fig:acc）。事前学習済みモデルの比較では、CLIPモデルが最も高い予測精度を示し、予測と実際の評価との相関係数は*r = 0.78*であった。一方、事前学習のみのDCNNモデルはそれぞれConvNeXt *r = 0.63*、ResNet *r = 0.44*、VGG *r = 0.19*と低い精度を示した。食品評価データでファインチューニングを行った結果、DCNNモデルの予測精度は大幅に向上し、ConvNeXt *r = 0.69*、ResNet *r = 0.61*、VGG *r = 0.58*となった。これらの結果は、CLIPが事前学習のみで高い予測精度を達成する一方、DCNNはファインチューニングにより性能が向上することを示している。

    #figure(
      image("./image/cv_barplot_pretrained_vs_finetuned.png", width: 80%),
      supplement: figure_supplement,
      caption: [DNNモデルによる主観的価値予測の精度（予測と実際の評価との相関係数）。青：事前学習のみ、緑：ファインチューニング後。CLIPは事前学習済みモデルのみ使用。],
    ) <fig:acc>

    == DNNの層別情報表現
    ファインチューニング後のConvNeXtモデルおよび事前学習済みCLIPモデルの各層における情報表現を分析し、異なる種類の情報（低次画像特徴、栄養属性、美味しさ、健康性、主観的価値）がどの層で表現されているかを調査した。各層について、主成分分析（PCA）を適用し、得られた主成分をリッジ回帰の予測子として使用して各属性を推定した。 層ごとの説明力（予測と実際の評価との相関係数）を計算し、@fig:repr1 に示すように、各属性の層別表現を評価した。 高次属性（主観的価値、美味しさ、健康性）は初期層での説明力が低く、後期層で増加する傾向が見られた。一方、低次の色情報（赤、緑、青）は初期層で高い説明力を示し、後期層でも情報が保持されていた。栄養属性はConvNeXtでは全体的に弱い表現を示したが、CLIPでは後期層で説明力が増加した。

    #let side_by_side(
      left_img,
      left_label,
      right_img,
      right_label,
      main_caption,
      columns: 2,
      gutter: 12%,
    ) = {
      subpar.grid(
        columns: columns,
        supplement: figure_supplement,
        numbering-sub: "a.",
        align: top,
        show-sub-caption: (num, it) => {
          set text(size: 0.8em)
          set align(left)
          text(weight: "bold", num)
        },
        show-sub: it => {
          set figure.caption(position: top)
          it
        },
        figure(
          left_img,
          supplement: figure_supplement,
          caption: [],
        ),
        left_label,
        figure(
          right_img,
          supplement: figure_supplement,
          caption: [],
        ),
        right_label,

        caption: main_caption,
        gutter: gutter,
      )
    }

    #figure(
      grid(
        image("./image/encoding_lineplot_pretrained_vs_finetuned.png", width: 130%),
        image("./image/encoding_lineplot_clip_36layers.png", width: 119%),

        columns: 2,
        gutter: 12%,
      ),
      supplement: figure_supplement,
      caption: [DNNモデルの各層における情報表現。左：ファインチューニング後のConvNeXt、右：事前学習済みCLIP。各線は、各属性の予測と実際の評価との相関係数を示す。],
    ) <fig:repr1>

    これらの結果は、ファインチューニング後のConvNeXtおよび事前学習済みCLIPモデルにおいて、高次属性が後期層で主に表現され、低次の色情報が初期層で強く表現される傾向があることを示している。なお、事前学習済み（ファインチューニングなし）のConvNeXtモデルについても同様の分析を行った結果を@app10 に示す。

    == fMRI解析結果

    === 主観的価値に関連する脳活動
    GLM解析により、食品画像に対する主観的価値評価と有意に相関する脳領域を同定した。主観的価値のパラメトリックモジュレーター（Image × Value）について、クラスターレベルFWE補正（p < 0.05、クラスター形成閾値p < 0.001 uncorrected）を適用した結果、*87個の有意なクラスター*（総ボクセル数11,697、ピークT値6.80）が検出された（@fig:glm_value）。

    活性化は広範な脳領域で観察され、特に後頭葉の視覚関連領域（一次視覚野、外側後頭皮質、紡錘状回）、側頭葉（下側頭回）、前頭葉（腹内側前頭前皮質、眼窩前頭皮質）、および頭頂葉で顕著であった。これらの結果は、食品の主観的価値評価が視覚処理から価値表現に至る広範なネットワークを動員することを示唆している。

    #figure(
      image("./image/glm_rgb_nutri_ImagexValue.png", width: 100%),
      supplement: figure_supplement,
      caption: [主観的価値（Image × Value）に関連する脳活動。クラスターレベルFWE補正（p < 0.05、クラスター形成閾値p < 0.001 uncorrected）。カラーバーはT値を示す。色付きの輪郭線は関心領域（ROI）を示す：vmPFC（青）、OFC（緑）、左線条体（シアン）、右線条体（マゼンタ）。],
    ) <fig:glm_value>

    === ROI解析
    先行研究に基づいて定義した関心領域（ROI）における主観的価値の効果を検証した。Small Volume Correction（SVC）を適用したROI解析の結果、価値処理に関連する複数の領域で有意な効果が認められた（@fig:roi_value）。

    腹内側前頭前皮質（vmPFC）では有意な効果が観察され、主観的価値の表出に関与することが確認された。内側眼窩前頭皮質（mOFC）でも有意な効果が認められた。さらに、左右の線条体でも有意な効果が観察され、報酬処理への関与が示唆された。

    島皮質および扁桃体でも統計的に有意な効果が認められた。これらの結果は、食品の主観的価値がvmPFC、mOFC、線条体に加え、島皮質や扁桃体を含む広範な脳領域で表現されることを示している。

    #figure(
      image("./image/roi_effectsize_rgb_nutri_ImagexValue.png", width: 80%),
      supplement: figure_supplement,
      caption: [ROI解析における主観的価値の効果量（β）。すべてのROIで有意な効果が認められた（p < 0.05）。vmPFC：腹内側前頭前皮質、mOFC：内側眼窩前頭皮質。],
    ) <fig:roi_value>
    === DNN比較分析
    DNNの内部表現とfMRIデータの脳活動パターンを比較するために、表現類似性解析（RSA）と3レベル階層的PCAを用いたエンコーディング解析を行った。

    ==== 表現類似性解析（RSA）
    DNNの内部表現と脳活動パターンの構造的類似性を評価するため、関心領域（ROI）ベースの表現類似性解析（RSA）を実施した。各ROIにおいて、490枚の食品画像に対するベータ値から表現類似度行列（RDM）を構築し、DNNの各層の活性化パターンから同様に算出したRDMとのスピアマン相関を計算した。

    モデルの説明力を評価するため、Leave-One-Out法によるノイズ上限値（NC）を算出した。NC上限は各被験者と全被験者平均RDMとの相関、NC下限は各被験者と残りの被験者の平均RDMとの相関として定義した。NC上限比（モデル相関 / NC上限 × 100）により、理論的に達成可能な最大説明力に対するモデルの到達度を評価した。

    ===== ROI-RSA結果
    Double-centeringを適用したRSA解析の結果、視覚野において最も高い説明率が観察された。V1では3モデルとも約65-69%の説明率を達成し、CLIPが67.0%、ImageNetが64.3%、Foodが68.7%であった。初期視覚野でも同様に、CLIPが62.5%、ImageNetが63.5%、Foodが68.7%の説明率を示した。

    全31 ROIにおける平均説明率を比較すると、CLIPモデルが13.9%で最も高く、Foodモデル（12.9%）、ImageNetモデル（12.0%）が続いた（右）。統計検定の結果、CLIPとImageNetの間には有意差が認められ（対応のあるt検定、t(30) = 7.05、p < 0.001）、FoodとImageNetの間にも有意差が認められた（t(30) = 2.10、p = 0.045）。一方、視覚野のみ（n=5）での比較では、3モデル間に有意差は認められなかった（CLIP vs ImageNet: p = 0.059）。

    高次視覚野および価値関連領域では説明率が低下した。LOC（CLIP: 36.9%、ImageNet: 32.2%、Food: 29.0%）、紡錘状回（CLIP: 39.1%、ImageNet: 35.2%、Food: 30.7%）では約30-40%の説明率に留まった。vmPFC（CLIP: 4.7%、ImageNet: 3.9%、Food: 8.0%）ではさらに低い値を示した。

    これらの結果は、DNNモデルが初期視覚野の表現構造を高い精度で説明できる一方、高次領域および価値関連領域の表現については未説明の分散が大きいことを示唆している。また、CLIPモデルが全ROI平均で最も高い説明率を示したことは、視覚-言語モデルが脳の表現構造をより広範に捉えている可能性を示している。

    #side_by_side(
      image("./image/rsa_roi_centered_comparison_jp.png", width: 110%),
      <fig:rsa_roi_centered>,
      image("./image/rsa_roi_centered_summary_jp.png", width: 95%),
      <fig:rsa_roi_centered>,
      "ROI-RSA解析結果（Double-centering適用）。a. 各ROIにおけるモデル別説明率の比較。b. 右は視覚野（V1、初期視覚野、LOC、紡錘状回、IT）における平均説明率。左は全31 ROIにおける平均説明率。エラーバーは標準誤差（SEM）。*** p < 0.001、* p < 0.05（対応のあるt検定）。",
      columns: 1,
      gutter: 0%,
    )

    ==== エンコーディング解析

    ===== ConvNeXtモデル
    ConvNeXtモデルの階層的解析結果を@fig:convnext_hierarchical に示す。各層グループに関連する共有成分を加えた解析の結果、初期層は後頭葉の一次視覚野（V1）および外側後頭皮質で有意な効果を示した。中間層は側頭葉および頭頂葉で活性化を示した。後期層は広範な活性化を示し、視覚野から側頭葉、頭頂葉にわたる領域で有意な効果が認められた。最終層は最も広範な活性化を示し、腹内側前頭前皮質（vmPFC）を含む前頭葉領域でも有意な効果が認められた。

    これらの結果は、ConvNeXtの階層構造が脳の視覚処理階層と対応しており、初期層が低次視覚野、後期層が高次視覚野および価値関連領域と相関することを示唆している。

    ===== CLIPモデル
    CLIPモデルの階層的解析結果を@fig:clip_hierarchical に示す。初期層は後頭葉で最も強い活性化を示した。中間層は側頭葉および頭頂葉で広範な活性化を示し、視覚的オブジェクト認識に関連する領域との対応が示唆された。後期層および最終層は、ConvNeXtと比較して限定的な活性化パターンを示した。

    CLIPモデルでは、視覚野から側頭葉にかけての領域と強く相関することが示された。初期層から中間層にかけての広範な活性化は、CLIPの学習方法の特性を反映している可能性がある。

    #side_by_side(
      image("./image/convnext_hierarchical_fwe_p0.05.png", width: 135%),
      <fig:convnext_hierarchical>,
      image("./image/clip_hierarchical_fwe_p0.05.png", width: 135%),
      <fig:clip_hierarchical>,
      "DNNモデルの層グループ別脳活動（FWE補正 p < 0.05）。a. ConvNeXtモデル。b. CLIPモデル。各行は異なる層グループ（初期層+共有、中間層+共有、後期層+共有、最終層+共有）と脳活動の対応を示す。",
    )

    ===== DNN層グループとROIの対応
    DNNの各層グループと関心領域（ROI）の対応関係を詳細に検討するため、Small Volume Correction（SVC）を用いたROI解析を行った（@fig:roi_barplot）。

    視覚野（V1、初期視覚野、LOC、紡錘状回、IT、海馬傍回）@Grill-Spector2004 @Kravitz2013 では、両モデルとも複数の層グループで有意な対応を示した（SVC FWE p < 0.05）。ConvNeXtではV1、初期視覚野、LOC、ITが全層で有意であり、紡錘状回は中間層以降、海馬傍回は後期層以降で有意であった。CLIPではV1と初期視覚野が全層で有意であり、LOCは初期・中間・最終層、紡錘状回は初期・中間層で有意であった。

    空間注意系（SPL）@Corbetta2002 では、ConvNeXtでSPLが中間層以降で有意であった。CLIPでは有意な対応は認められなかった。

    記憶系（PCC）では、ConvNeXtで後期層以降、CLIPでは中間層で有意な対応が認められた。

    言語野（IFG、MTG、STG、側頭極、角回）@Fedorenko2024 では、CLIPの中間層でIFGおよび左角回に有意な対応が認められた。ConvNeXtでも後期層以降で左角回に有意な対応が認められた。この左角回の効果は、視覚-言語モデル（CLIP）が視覚皮質活動を説明する際に左角回との接続が重要であることを示した先行研究@Chen2025 と整合する。

    報酬系（NAcc、OFC）@Haber2010 では、ConvNeXtは後期層以降でNAcc、最終層でOFCと有意な対応を示した。CLIPでは中間層でNAccとOFC、最終層でもNAccに有意な対応が認められた。

    価値判断系（vmPFC、DLPFC）@Kahnt2010 では、ConvNeXtの後期層以降でvmPFCとDLPFCに有意な対応が認められた。CLIPでは有意な対応は認められなかった。

    注意選択系（扁桃体、島皮質、ACC）@Seeley2007 @MORAWETZ2017111 では、ConvNeXtでは有意な対応は認められなかった。一方、CLIPでは中間層で扁桃体、島皮質、ACCすべてに有意な対応が認められた。

    習慣学習系（尾状核、被殻）では、CLIPの中間層でのみ有意な対応が認められた。

    これらの結果から、ConvNeXtは視覚処理の階層構造に沿って情報を処理し、後期層で価値判断系、空間注意系、記憶系と対応するのに対し、CLIPでは中間層で報酬系、注意選択系、習慣学習系、記憶系との対応が認められた。


    #figure(
      image("./image/roi_rms_barplot_withshared.png", width: 110%),
      supplement: figure_supplement,
      caption: [DNNモデルの層グループ別ROI効果量。各層（初期・中間・後期・最終）に関連する共有成分を加えた効果量を示す。エラーバーは被験者間の標準誤差（SEM）。は有意な効果（SVC FWE p < 0.05）。追加の効果量図は @app11[補足] を参照。],
    ) <fig:roi_barplot>

    = 考察

    本研究では、DNNを用いて食品画像から主観的価値を予測し、その内部表現と脳活動パターンを比較することで、食品評価の神経計算基盤を検討した。主要な発見は以下の通りである。第一に、CLIPモデルが最も高い予測精度（r = 0.78）を示し、視覚-言語統合が食品の価値予測に重要であることが示された。第二に、DNNの層別解析により、高次属性（美味しさ、健康性、主観的価値）は後期層で、低次の色情報は階層全体を通じて表現されることが明らかになった。第三に、ROI-RSA解析により、DNNモデルは初期視覚野の表現構造を高い精度で説明できる（V1で65-69%）一方、価値関連領域（vmPFC: 4-8%）では説明力が低いことが示された。第四に、エンコーディング解析により、ConvNeXtは視覚処理階層に沿った対応を示し、CLIPはより早期の層で情動・報酬・言語関連領域との対応を示した。

    DCNNの活性化における栄養属性の弱い表現は、主観的な栄養情報が主観的価値の予測に寄与することを示した先行研究@Suzuki2017-wk とは対照的である。一方で、CLIPでは栄養価が高次層で説明力が高くなっていたことから、視覚モデルでは栄養情報が抽出できないが、視覚-言語モデルでは栄養情報が抽出できることが示唆された。これは、CLIPがTransformerを含み膨大なWeb上のデータを学習していることに起因し、意味情報の逆伝播によって画像の視覚情報から栄養情報を読み取ることを可能にしている可能性がある。


    fMRI解析において、主観的価値評価に関連する脳領域として、視覚野（V1、LOC、紡錘状回）、前頭葉（vmPFC、OFC）、および線条体が同定された。ROI解析では、vmPFCおよび線条体が主観的価値の表出に重要な役割を果たすことが確認された。これらの結果は、先行研究における価値表現の知見と一致している@Suzuki2017-wk @Hare5623 @Chib2009-jq。

    情報表現のパターンは、視覚芸術の価値評価に関する先行研究@Iigaya2021 の知見とは異なる。先行研究では、色情報は主に初期層で表現され、後期層では減少することが示されている。本研究では、食品画像において色がより持続的かつ影響力のある役割を果たし、階層的処理を通じて後期層まで説明力が維持された。この違いは、食品評価における色の重要性に起因する可能性がある。ヒトの三色型色覚は食物採集能力を向上させるために進化したと考えられており、食品の色は栄養価や鮮度を示すシグナルとして機能する@Foroni2016。

    RSA解析の結果、DNNモデルは視覚野との類似度が高い一方、価値関連領域の表現についてはうまく説明できないことが示された。DCNNと脳のマッピングを試みた研究では、視覚領域における説明可能な分散の60%以上が説明されており@Dwivedi2021、本研究のV1における結果は先行研究と一致する。一方、vmPFCにおいて説明率が4-8%と低い値を示したことは、価値計算が視覚情報処理以外の多様な情報（感情、記憶、社会的文脈）を統合する複雑なプロセスであり、現在のDNNモデルではこれらの要素を十分に反映できていない可能性を示唆している。

    エンコーディング解析の結果、CLIPモデルでは、より早期の層（中間層）で情動・報酬関連領域との対応を形成した。CLIPの中間層は、感情制御に関わるPCC・扁桃体・島皮質・ACC@MORAWETZ2017111、言語処理の中核であるIFG@Fedorenko2024、および意味処理に関わる左角回と有意な対応を示した。特に左角回との対応は、CLIPが腹側後頭側頭皮質（VOTC）の活動を説明する際に左角回との白質接続が重要であるという先行研究@Chen2025 と整合し、食品の主観的価値計算における言語的・意味的情報の統合を支持する。これらの結果は、食品評価において経験・言語・感情が価値計算に寄与することを示唆しており、感情制御@Morawetz2021 や食品ラベル@Grabenhorst2013 が食品評価を変化させるという知見とも一致する。

    本研究の解釈にはいくつかの方法論的限界がある。第一に、CLIPモデルは学習データ（LAION-400M vs ImageNet-1K）と学習タスク（対照学習 vs 分類）の両方がImageNetモデルと異なるため、これらの効果を分離することは困難である。ただし、本研究では同一のConvNeXt-Baseアーキテクチャを使用しており、構造的な交絡は排除されている。また、事前学習データのスケールの違い（128万 vs 4億枚）は予測精度の差に影響しうるが、モデル内の階層的な情報表現構造や脳領域との対応関係は、データスケールよりもアーキテクチャに依存することが示されている@StYves2023。実際、両モデルで類似した階層構造（初期層で低次視覚特徴、後期層で高次属性を表現）が観察された。今後の研究では、対照学習で学習したImageNetモデルなどを用いて、学習データと学習方法の効果を分離して検討する必要がある。

    第二に、DNNの最終層ではなく中間〜後期層で脳との対応が最大になる点について、解釈には注意が必要である。この現象は、最終層が分類タスクに過剰に特化していることを反映している可能性がある一方、脳の視覚処理が再帰的な情報統合を含むことを示唆している可能性もある。これらの解釈を区別するには、再帰接続を明示的にモデル化したDNNとの比較が必要である。

    第三に、本研究は相関解析に基づいており、DNNと脳が類似した計算を行っているという因果的結論を導くことはできない。経頭蓋磁気刺激法 (TMS) や動物実験などで、因果関係の検証もしくは、動的因果モデリング（DCM）を用いた情報フローの解析が今後の課題である。

    第四に、DCNNは食品に関する意味的・概念的知識を直接エンコードせず、重要な点で人間の視覚と異なる可能性がある@Bowers2023 @Caplette2024。今回のRSA解析では、CLIPモデルが他のDNNモデルよりも高い説明力を示したが、高次領域での説明力は依然として低かった。そのため、将来的には、視覚情報と概念的知識や感情情報を統合した専門領域モデルを組み合わせたマルチモーダルモデルの開発が期待される。

    また、本研究では全参加者の平均評価を使用したが、特定の集団（肥満者や特異な食習慣を持つ個人）への解析の拡張は重要な方向性である。先行研究では、肥満や摂食障害において嗜好が異なる可能性が示唆されており@Foerde2015 @Spinelli2021-yi、集団間で視覚特徴の重み付けや価値評価プロセスに違いがある可能性がある。

    本研究は、DNNを用いた計算論的アプローチにより、食品画像からの主観的価値計算における視覚情報処理の階層構造を明らかにした。fMRIデータとDNNとの比較では、初期視覚野（V1）においてノイズ上限値の65-69%を説明できる一方、vmPFCでは4-8%に留まった。この結果は、現在のDNNモデルが視覚処理は捉えられるが、価値計算の神経基盤は十分に捉えられていないことを示している。ConvNeXtは視覚処理階層に沿った対応（初期層-V1、後期層-vmPFC）を示し、CLIPは中間層で情動・言語関連領域（扁桃体、島皮質、IFG、左角回）との対応を示した。CLIPモデルが最も高い予測精度（r = 0.78）と脳活動説明力を示したことは、視覚-言語統合が食品評価において重要な役割を果たすことを示唆している。これらの知見は、食品選択の神経計算基盤の理解に貢献し、将来的には肥満や摂食障害などの食事関連疾患への応用が期待される。

    = 付録
    #show: appendix

    #include "appendix.typ"
    #bibliography("./ref.bib", style: "apa", title: "引用文献")
  ],
)
